{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_corpus\n",
    "import mwu_functions\n",
    "from importlib import reload\n",
    "mwu_functions = reload(mwu_functions)\n",
    "from collections import defaultdict\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the corpus\n",
      "Reading and cleaning corpus...\n",
      "44537 lines processed\n",
      "88073 lines processed\n",
      "133167 lines processed\n",
      "178348 lines processed\n",
      "216824 lines processed\n",
      "251138 lines processed\n",
      "287603 lines processed\n",
      "331019 lines processed\n",
      "375948 lines processed\n",
      "417432 lines processed\n",
      "466306 lines processed\n",
      "515745 lines processed\n",
      "570565 lines processed\n",
      "613855 lines processed\n",
      "650149 lines processed\n",
      "688628 lines processed\n",
      "729956 lines processed\n",
      "771778 lines processed\n",
      "818426 lines processed\n",
      "859531 lines processed\n",
      "905554 lines processed\n",
      "942904 lines processed\n",
      "990472 lines processed\n",
      "1047140 lines processed\n",
      "1081408 lines processed\n",
      "1123311 lines processed\n",
      "1188231 lines processed\n",
      "1235032 lines processed\n",
      "1284936 lines processed\n",
      "1333331 lines processed\n",
      "1386074 lines processed\n",
      "1429378 lines processed\n",
      "1475285 lines processed\n",
      "1524768 lines processed\n",
      "1571261 lines processed\n",
      "1622600 lines processed\n",
      "1666990 lines processed\n",
      "1725788 lines processed\n",
      "1764656 lines processed\n",
      "1809099 lines processed\n",
      "1847206 lines processed\n",
      "1884763 lines processed\n",
      "1922707 lines processed\n",
      "1961277 lines processed\n",
      "2001483 lines processed\n",
      "2040108 lines processed\n",
      "2078632 lines processed\n",
      "2120356 lines processed\n",
      "2159410 lines processed\n",
      "2197863 lines processed\n",
      "2239881 lines processed\n",
      "2289988 lines processed\n",
      "2334338 lines processed\n",
      "2373494 lines processed\n",
      "2416576 lines processed\n",
      "2463580 lines processed\n",
      "2503175 lines processed\n",
      "2537323 lines processed\n",
      "2570926 lines processed\n",
      "2608790 lines processed\n",
      "2655201 lines processed\n",
      "2690157 lines processed\n",
      "2726762 lines processed\n",
      "2759447 lines processed\n",
      "2809268 lines processed\n",
      "2861842 lines processed\n",
      "2905673 lines processed\n",
      "2953984 lines processed\n",
      "2997420 lines processed\n",
      "3046510 lines processed\n",
      "3099765 lines processed\n",
      "3145718 lines processed\n",
      "3200936 lines processed\n",
      "3259797 lines processed\n",
      "3308411 lines processed\n",
      "3376347 lines processed\n",
      "3434146 lines processed\n",
      "3475389 lines processed\n",
      "3518985 lines processed\n",
      "3566660 lines processed\n",
      "3609889 lines processed\n",
      "3654804 lines processed\n",
      "3721721 lines processed\n",
      "3770388 lines processed\n",
      "3804849 lines processed\n",
      "3855436 lines processed\n",
      "3900126 lines processed\n",
      "3938107 lines processed\n",
      "3995170 lines processed\n",
      "4033278 lines processed\n",
      "4081150 lines processed\n",
      "4130680 lines processed\n",
      "4166281 lines processed\n",
      "4237474 lines processed\n",
      "4352733 lines processed\n",
      "4416873 lines processed\n",
      "4507885 lines processed\n",
      "4623039 lines processed\n",
      "4699422 lines processed\n",
      "4747161 lines processed\n",
      "4786878 lines processed\n",
      "4823644 lines processed\n",
      "4900875 lines processed\n",
      "5011574 lines processed\n",
      "5107802 lines processed\n",
      "5156063 lines processed\n",
      "5198949 lines processed\n",
      "5241362 lines processed\n",
      "5287429 lines processed\n",
      "5333458 lines processed\n",
      "5375272 lines processed\n",
      "5416759 lines processed\n",
      "5463006 lines processed\n",
      "5505493 lines processed\n",
      "5543557 lines processed\n",
      "5581661 lines processed\n",
      "5619313 lines processed\n",
      "5668857 lines processed\n",
      "5714439 lines processed\n",
      "5759362 lines processed\n",
      "5798103 lines processed\n",
      "5839038 lines processed\n",
      "5878169 lines processed\n",
      "5921274 lines processed\n",
      "5963763 lines processed\n",
      "6006576 lines processed\n",
      "6026276 lines processed\n",
      "Getting everything ready for score extraction\n"
     ]
    }
   ],
   "source": [
    "process_corpus.process_corpus(corpus='bnc', corpus_dir='bnc_tokenized.txt', verbose=True, chunk_size = 5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_functions.get_mwu_scores([\"i don't\", 'i care', 'i go', 'you go', \"they don't\", \"the highway\", \"a highway\"], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_fw = defaultdict(list)\n",
    "for _, corpus_dict in process_corpus.bigram_fw.items():\n",
    "    for bigram, freq in corpus_dict.items():\n",
    "        consolidated_fw[bigram].append(freq)\n",
    "\n",
    "consolidated_bw = defaultdict(list)\n",
    "for _, corpus_dict in process_corpus.bigram_bw.items():\n",
    "    for bigram, freq in corpus_dict.items():\n",
    "        consolidated_bw[bigram].append(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_fw = defaultdict(FreqDist)\n",
    "for _, corpus_dict in process_corpus.bigram_fw.items():\n",
    "    for bigram, freq in corpus_dict.items():\n",
    "        consolidated_fw[bigram].update(freq)\n",
    "\n",
    "consolidated_bw = defaultdict(FreqDist)\n",
    "for _, corpus_dict in process_corpus.bigram_bw.items():\n",
    "    for bigram, freq in corpus_dict.items():\n",
    "        consolidated_bw[bigram].update(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_fw = {bigram: sum(freq_dists, FreqDist()) for bigram, freq_dists in consolidated_fw.items()}\n",
    "consolidated_bw = {bigram: sum(freq_dists, FreqDist()) for bigram, freq_dists in consolidated_bw.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token = max([freq[freq.max()] for freq in consolidated_fw.values()])\n",
    "min_token = 1\n",
    "\n",
    "typef_1_all = [freq.B() for freq in consolidated_bw.values()]\n",
    "typef_1_max = max(typef_1_all)\n",
    "typef_1_min = min(typef_1_all)\n",
    "\n",
    "typef_2_all = [freq.B() for freq in consolidated_fw.values()]\n",
    "typef_2_max = max(typef_2_all)\n",
    "typef_2_min = min(typef_2_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typef_1_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consolidate, then sum: 28s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(consolidated_bigrams['small'], FreqDist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Documentation\n",
    "#TODO: Division by zero in log2\n",
    "#TODO: Scale to trigrams\n",
    "#TODO: memory profiling\n",
    "#TODO: Simplify selection of chunk size in reading corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwu_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
