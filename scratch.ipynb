{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88073 lines processed\n",
      "178347 lines processed\n",
      "251137 lines processed\n",
      "331017 lines processed\n",
      "417430 lines processed\n",
      "515742 lines processed\n",
      "613852 lines processed\n",
      "688626 lines processed\n",
      "771777 lines processed\n",
      "859529 lines processed\n",
      "942900 lines processed\n",
      "1047131 lines processed\n",
      "1123302 lines processed\n",
      "1235027 lines processed\n",
      "1333326 lines processed\n",
      "1429373 lines processed\n",
      "1524762 lines processed\n",
      "1622597 lines processed\n",
      "1725782 lines processed\n",
      "1809093 lines processed\n",
      "1884758 lines processed\n",
      "1961270 lines processed\n",
      "2040098 lines processed\n",
      "2120332 lines processed\n",
      "2197854 lines processed\n",
      "2289980 lines processed\n",
      "2373487 lines processed\n",
      "2463569 lines processed\n",
      "2537313 lines processed\n",
      "2608775 lines processed\n",
      "2690149 lines processed\n",
      "2759435 lines processed\n",
      "2861830 lines processed\n",
      "2953964 lines processed\n",
      "3046485 lines processed\n",
      "3145655 lines processed\n",
      "3259778 lines processed\n",
      "3376309 lines processed\n",
      "3475369 lines processed\n",
      "3566620 lines processed\n",
      "3654773 lines processed\n",
      "3770351 lines processed\n",
      "3855412 lines processed\n",
      "3938084 lines processed\n",
      "4033231 lines processed\n",
      "4130649 lines processed\n",
      "4237372 lines processed\n",
      "4416828 lines processed\n",
      "4622940 lines processed\n",
      "4747128 lines processed\n",
      "4823611 lines processed\n",
      "5011537 lines processed\n",
      "5156032 lines processed\n",
      "5241328 lines processed\n",
      "5333426 lines processed\n",
      "5416742 lines processed\n",
      "5505469 lines processed\n",
      "5581625 lines processed\n",
      "5668824 lines processed\n",
      "5759333 lines processed\n",
      "5838998 lines processed\n",
      "5921184 lines processed\n",
      "6006547 lines processed\n",
      "6026276 lines processed\n",
      "we bring the boom\n"
     ]
    }
   ],
   "source": [
    "import mwu_measures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mwu_measures.processing_corpus\n",
    "from mwu_measures.corpus_helper import Fetcher\n",
    "\n",
    "mwu_examples = pd.read_csv('MultiwordExpression_Concreteness_Ratings.csv')\n",
    "mwu_examples['length'] = mwu_examples['Expression'].apply(lambda x: len(x.split()))\n",
    "mwu_examples = mwu_examples.loc[(mwu_examples['length'] == 2) | (mwu_examples['length'] == 3)]\n",
    "mwu_examples['Expression'] = mwu_examples['Expression'].apply(lambda x: x.lower())\n",
    "this_corpus = mwu_measures.processing_corpus.process_corpus('bnc', 'bnc_tokenized.txt', chunk_size=10000000, verbose=True)\n",
    "this_corpus.create_totals()\n",
    "ngram_selection = mwu_examples['Expression'].tolist()\n",
    "bigrams = [ngram for ngram in ngram_selection if len(ngram.split()) == 2]\n",
    "# ngram_selection = [ngram.split() for ngram in ngram_selection]\n",
    "# ngram_chunks = np.array_split(ngram_selection, 100)\n",
    "\n",
    "\n",
    "# this_corpus = mwu_measures.processing_corpus.process_corpus(test_corpus=True)\n",
    "# bigrams = ['b d', 'c b', 'a c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.22 caliber',\n",
       " '.38 caliber',\n",
       " '1 kgs',\n",
       " '1 samuel',\n",
       " '1 timothy',\n",
       " '10-undecenoic acid',\n",
       " '18-karat gold',\n",
       " '1st class',\n",
       " '1st-class mail',\n",
       " '20/20 vision',\n",
       " '22-karat gold',\n",
       " '30 minutes',\n",
       " '365 days',\n",
       " '3d printer',\n",
       " '3d scanner',\n",
       " '4-3 suspension',\n",
       " '4-h club',\n",
       " '8 ball',\n",
       " '800 number',\n",
       " 'a battery',\n",
       " 'a bit',\n",
       " 'a blowhard',\n",
       " 'a bunch',\n",
       " 'a capella',\n",
       " 'a cappella',\n",
       " 'a couple',\n",
       " 'à deux',\n",
       " 'a doddle',\n",
       " 'a drive',\n",
       " 'a few',\n",
       " 'a fortiori',\n",
       " 'a freak-out',\n",
       " 'a further',\n",
       " 'a getaway',\n",
       " 'a go',\n",
       " 'a goner',\n",
       " 'a good',\n",
       " 'a goof-off',\n",
       " 'a handful',\n",
       " 'a hang-up',\n",
       " 'a heart-to-heart',\n",
       " 'a heel',\n",
       " 'a high-flyer',\n",
       " 'a kickback',\n",
       " 'à la',\n",
       " 'a level',\n",
       " 'a little',\n",
       " 'a lot',\n",
       " 'a major',\n",
       " 'a mere',\n",
       " 'a must',\n",
       " 'a no-brainer',\n",
       " 'a norange',\n",
       " 'a one',\n",
       " 'a pair',\n",
       " 'a peach',\n",
       " 'a pleasure',\n",
       " 'a plus',\n",
       " 'a posteriori',\n",
       " 'a priori',\n",
       " 'a propos',\n",
       " 'a put-down',\n",
       " 'a rip-off',\n",
       " 'a roll',\n",
       " 'a sec',\n",
       " 'a shame',\n",
       " 'a single',\n",
       " 'a smokescreen',\n",
       " 'a sport',\n",
       " 'a stretch',\n",
       " 'a student',\n",
       " 'a to-do',\n",
       " 'a ton',\n",
       " 'a tongue-lashing',\n",
       " 'a touch',\n",
       " 'a treat',\n",
       " 'a trifle',\n",
       " 'a while',\n",
       " 'a-d conversion',\n",
       " 'a-flat minor',\n",
       " 'a-frame house',\n",
       " 'a-frame tent',\n",
       " 'a-sharp major',\n",
       " 'a.n. other',\n",
       " 'a2 level',\n",
       " 'ab extra',\n",
       " 'ab inconvenienti',\n",
       " 'ab initio',\n",
       " 'abandon ship',\n",
       " 'abandoned infant',\n",
       " 'abasia atactica',\n",
       " 'abate of',\n",
       " 'abb wool',\n",
       " 'abbot general',\n",
       " 'abdominal cavity',\n",
       " 'abdominal muscle',\n",
       " 'abdominal pregnancy',\n",
       " 'abdominal quadrant',\n",
       " 'abdominal strap',\n",
       " 'abdominal wall',\n",
       " 'abdominodiaphragmatic breathing',\n",
       " 'abdominoperineal resection',\n",
       " 'abductor muscle',\n",
       " 'abductor oculi',\n",
       " 'abide by',\n",
       " 'abietic acid',\n",
       " 'ablative case',\n",
       " 'able bodied',\n",
       " 'able for',\n",
       " 'able rating',\n",
       " 'able seaman',\n",
       " 'abney level',\n",
       " 'abnormal psychology',\n",
       " 'abo system',\n",
       " 'abominable snowman',\n",
       " 'abortion pill',\n",
       " 'abortion right',\n",
       " 'abound in',\n",
       " 'abound with',\n",
       " 'about face',\n",
       " 'about time',\n",
       " 'about to',\n",
       " 'about turn',\n",
       " 'above all',\n",
       " 'above average',\n",
       " 'above board',\n",
       " 'above measure',\n",
       " 'above stealing',\n",
       " 'above water',\n",
       " 'above-the-line promotion',\n",
       " 'abrasive personality',\n",
       " 'abruptio placentae',\n",
       " 'abscissio infiniti',\n",
       " 'absence seizure',\n",
       " 'absent minded',\n",
       " 'absentee ballot',\n",
       " 'absentee landlord',\n",
       " 'absentee rate',\n",
       " 'absentee vote',\n",
       " 'absinthe oil',\n",
       " 'absolute altimeter',\n",
       " 'absolute ceiling',\n",
       " 'absolute form',\n",
       " 'absolute frequency',\n",
       " 'absolute humidity',\n",
       " 'absolute majority',\n",
       " 'absolute pitch',\n",
       " 'absolute system',\n",
       " 'absolute temperature',\n",
       " 'absolute term',\n",
       " 'absolute threshold',\n",
       " 'absolute value',\n",
       " 'absolute zero',\n",
       " 'absolutely not',\n",
       " 'absorbed dose',\n",
       " 'absorbent pad',\n",
       " 'absorption band',\n",
       " 'absorption cell',\n",
       " 'absorption coefficient',\n",
       " 'absorption factor',\n",
       " 'absorption indicator',\n",
       " 'absorption spectrum',\n",
       " 'abstract art',\n",
       " 'abstract artist',\n",
       " 'abstract entity',\n",
       " 'abstract expressionism',\n",
       " 'abstract expressionist',\n",
       " 'abstract idea',\n",
       " 'abstract model',\n",
       " 'abstract music',\n",
       " 'abstract nonsense',\n",
       " 'abstract noun',\n",
       " 'abstract term',\n",
       " 'abstract thought',\n",
       " 'abstract verb',\n",
       " 'abutment arch',\n",
       " 'abyssal zone',\n",
       " 'acacia tree',\n",
       " 'academic degree',\n",
       " 'academic freedom',\n",
       " 'academic gown',\n",
       " 'academic robe',\n",
       " 'academic session',\n",
       " 'academic term',\n",
       " 'academic year',\n",
       " 'academy award',\n",
       " 'academy awards',\n",
       " 'acaroid gum',\n",
       " 'accelerate off',\n",
       " 'acceleration principle',\n",
       " 'accelerator board',\n",
       " 'accelerator card',\n",
       " 'accelerator pedal',\n",
       " 'accent mark',\n",
       " 'accent pillow',\n",
       " 'accentual system',\n",
       " 'access code',\n",
       " 'access course',\n",
       " 'access number',\n",
       " 'access panel',\n",
       " 'access profile',\n",
       " 'access provider',\n",
       " 'access road',\n",
       " 'access route',\n",
       " 'access time',\n",
       " 'accessory cloud',\n",
       " 'accessory fruit',\n",
       " 'accessory nerve',\n",
       " 'accident prone',\n",
       " 'accident surgery',\n",
       " 'accidental death',\n",
       " 'accidental injury',\n",
       " 'accommodation centre',\n",
       " 'accommodation ladder',\n",
       " 'accomodate requirements',\n",
       " 'accompanied baggage',\n",
       " 'accomplished fact',\n",
       " 'accord with',\n",
       " 'according as',\n",
       " 'according to',\n",
       " 'accordion door',\n",
       " 'account book',\n",
       " 'account executive',\n",
       " 'account for',\n",
       " 'account holder',\n",
       " 'account name',\n",
       " 'account payable',\n",
       " 'account receivable',\n",
       " 'account statement',\n",
       " 'accounting firm',\n",
       " 'accounting package',\n",
       " 'accounts payable',\n",
       " 'accounts receivable',\n",
       " 'accredit with',\n",
       " 'accrual basis',\n",
       " 'accumulation point',\n",
       " 'accusative case',\n",
       " 'accused of',\n",
       " 'accustom to',\n",
       " 'accustomed to',\n",
       " 'ace inhibitor',\n",
       " 'ace it',\n",
       " 'acerate leaf',\n",
       " 'acetate disk',\n",
       " 'acetic acid',\n",
       " 'acetyl group',\n",
       " 'acetyltannic acid',\n",
       " 'ache for',\n",
       " 'ache over',\n",
       " 'achieve success',\n",
       " 'achilles heel',\n",
       " 'achilles tendon',\n",
       " \"achilles' heel\",\n",
       " 'achromatic color',\n",
       " 'achromatic colour',\n",
       " 'achromatic lens',\n",
       " 'achromatic vision',\n",
       " 'acid house',\n",
       " 'acid jazz',\n",
       " 'acid rain',\n",
       " 'acid rock',\n",
       " 'acid taste',\n",
       " 'acid test',\n",
       " 'ack-ack gun',\n",
       " 'ackee tree',\n",
       " 'acne cover',\n",
       " 'acne pimple',\n",
       " 'acne rosacea',\n",
       " 'acorn nut',\n",
       " 'acorn squash',\n",
       " 'acoustic buoy',\n",
       " 'acoustic coupler',\n",
       " 'acoustic emission',\n",
       " 'acoustic guitar',\n",
       " 'acoustic nerve',\n",
       " 'acoustic power',\n",
       " 'acoustic resistance',\n",
       " 'acoustic spectrum',\n",
       " 'acoustic velocity',\n",
       " 'acoustic wave',\n",
       " 'acquaintance rape',\n",
       " 'acquired taste',\n",
       " 'acquit oneself',\n",
       " 'acrocoracohumeral ligament',\n",
       " 'acromial process',\n",
       " 'across from',\n",
       " 'acrylic acid',\n",
       " 'acrylic fiber',\n",
       " 'act as',\n",
       " 'act for',\n",
       " 'act high-and-mighty',\n",
       " 'act on',\n",
       " 'act out',\n",
       " 'act reflexively',\n",
       " 'act superior',\n",
       " 'act up',\n",
       " 'act upon',\n",
       " 'acte gratuit',\n",
       " 'acting out',\n",
       " 'acting up',\n",
       " 'actinic ray',\n",
       " 'action figure',\n",
       " 'action film',\n",
       " 'action group',\n",
       " 'action man',\n",
       " 'action mechanism',\n",
       " 'action movie',\n",
       " 'action officer',\n",
       " 'action painting',\n",
       " 'action plant',\n",
       " 'action point',\n",
       " 'action potential',\n",
       " 'action replay',\n",
       " 'action research',\n",
       " 'action stations',\n",
       " 'action verb',\n",
       " 'activated sludge',\n",
       " 'active agent',\n",
       " 'active birth',\n",
       " 'active duty',\n",
       " 'active immunity',\n",
       " 'active ingredient',\n",
       " 'active list',\n",
       " 'active placebo',\n",
       " 'active service',\n",
       " 'active voice',\n",
       " 'active window',\n",
       " 'activist judge',\n",
       " 'activist justice',\n",
       " 'activity holiday',\n",
       " 'actor agent',\n",
       " 'actual eviction',\n",
       " 'actuarial table',\n",
       " 'acute accent',\n",
       " 'acute angle',\n",
       " 'acute glaucoma',\n",
       " 'acute triangle',\n",
       " 'ad absurdum',\n",
       " 'ad agency',\n",
       " 'ad campaign',\n",
       " 'ad hoc',\n",
       " 'ad hominem',\n",
       " 'ad infinitum',\n",
       " 'ad interim',\n",
       " 'ad lib',\n",
       " 'ad libitum',\n",
       " 'ad libs',\n",
       " 'ad loc.',\n",
       " 'ad nauseam',\n",
       " 'ad page',\n",
       " 'ad valorem',\n",
       " 'ad-hoc polymorphism',\n",
       " \"adam's ale\",\n",
       " \"adam's apple\",\n",
       " 'adapter pattern',\n",
       " 'adaptive optics',\n",
       " 'add bonus',\n",
       " 'add in',\n",
       " 'add on',\n",
       " 'add to',\n",
       " 'add together',\n",
       " 'add up',\n",
       " 'addams family',\n",
       " 'added value',\n",
       " \"adder's mouth\",\n",
       " \"adder's tongue\",\n",
       " 'adding machine',\n",
       " 'addis abeba',\n",
       " 'addition polymerization',\n",
       " 'addition reaction',\n",
       " 'addition sign',\n",
       " 'additive group',\n",
       " 'additive inverse',\n",
       " 'address bar',\n",
       " 'address book',\n",
       " 'adductor muscle',\n",
       " 'adenosine triphosphate',\n",
       " 'adequate to',\n",
       " 'ader wax',\n",
       " 'adhere to',\n",
       " 'adhesion contract',\n",
       " 'adhesive agent',\n",
       " 'adhesive bandage',\n",
       " 'adhesive material',\n",
       " 'adhesive tape',\n",
       " 'adiabatic gradient',\n",
       " 'adirondack chair',\n",
       " 'adjacent angle',\n",
       " 'adjacent to',\n",
       " 'adjectival group',\n",
       " 'adjective group',\n",
       " 'adjoining room',\n",
       " 'adjourn to',\n",
       " 'adjustable spanner',\n",
       " 'adjustable wrench',\n",
       " 'adjusting entry',\n",
       " 'adjutant general',\n",
       " 'adjutants general',\n",
       " 'administrative assistant',\n",
       " 'administrative official',\n",
       " 'administrative unit',\n",
       " \"admiral's cup\",\n",
       " 'admiralty law',\n",
       " 'admission charge',\n",
       " 'admission day',\n",
       " 'admission fee',\n",
       " 'admit of',\n",
       " 'admit to',\n",
       " 'adobe house',\n",
       " 'adoption agency',\n",
       " 'adoptive father',\n",
       " 'adoptive mother',\n",
       " 'adoptive parent',\n",
       " 'adrenal gland',\n",
       " 'adrenaline junkie',\n",
       " 'adsorbent material',\n",
       " 'aduki bean',\n",
       " 'adult body',\n",
       " 'adult education',\n",
       " 'adult female',\n",
       " 'adult intelligence',\n",
       " 'adult life',\n",
       " 'adult male',\n",
       " 'adult tooth',\n",
       " 'advance cheque',\n",
       " 'advance directive',\n",
       " 'advance guard',\n",
       " 'advance look',\n",
       " 'advance poll',\n",
       " 'advance warning',\n",
       " 'advance woman',\n",
       " 'advanced degree',\n",
       " 'advanced guard',\n",
       " 'advanced higher',\n",
       " 'advanced level',\n",
       " 'advanced placement',\n",
       " 'advent calendar',\n",
       " 'advent sunday',\n",
       " 'adventure education',\n",
       " 'adventure game',\n",
       " 'adventure holiday',\n",
       " 'adventure playground',\n",
       " 'adventure story',\n",
       " 'adventure tour',\n",
       " 'adventure travel',\n",
       " 'adverb group',\n",
       " 'adverb phrase',\n",
       " 'adverbial group',\n",
       " 'adverbial particle',\n",
       " 'adversarial system',\n",
       " 'adverse opinion',\n",
       " 'adverse witness',\n",
       " 'advertising agency',\n",
       " 'advertising campaign',\n",
       " 'advertising department',\n",
       " 'advertising firm',\n",
       " 'advice boat',\n",
       " 'advice column',\n",
       " 'advice columnist',\n",
       " 'advice line',\n",
       " 'advisory board',\n",
       " 'advisory opinion',\n",
       " 'advisory service',\n",
       " 'advocacy group',\n",
       " 'adzuki bean',\n",
       " 'aeolian harp',\n",
       " 'aerial cableway',\n",
       " 'aerial root',\n",
       " 'aerobic respiration',\n",
       " 'aerodynamic lift',\n",
       " 'aerosol can',\n",
       " 'afar off',\n",
       " \"affaire d'honneur\",\n",
       " 'affect perseverance',\n",
       " 'affective disorder',\n",
       " 'afferent fiber',\n",
       " 'afferent nerve',\n",
       " 'affidavit men',\n",
       " 'affiliate marketing',\n",
       " 'affine geometry',\n",
       " 'affine group',\n",
       " 'affine transformation',\n",
       " 'affinity card',\n",
       " 'affinity group',\n",
       " 'affirmative action',\n",
       " 'affirmative pleading',\n",
       " 'afford to',\n",
       " 'affordable housing',\n",
       " 'afghan hound',\n",
       " 'afoul of',\n",
       " 'african american',\n",
       " 'african canadian',\n",
       " 'african caribbean',\n",
       " 'african crake',\n",
       " 'african renaissance',\n",
       " 'african violet',\n",
       " 'africanist dance',\n",
       " 'afro hairdo',\n",
       " 'afro wig',\n",
       " 'afro-seminole creole',\n",
       " 'after all',\n",
       " 'after hours',\n",
       " 'after part',\n",
       " 'after party',\n",
       " 'after-sales service',\n",
       " 'after-shave lotion',\n",
       " 'afternoon shift',\n",
       " 'afternoon tea',\n",
       " 'aga saga',\n",
       " 'agape love',\n",
       " 'age bracket',\n",
       " 'age class',\n",
       " 'age discrimination',\n",
       " 'age gap',\n",
       " 'age group',\n",
       " 'age limit',\n",
       " 'age norm',\n",
       " 'age pension',\n",
       " 'age range',\n",
       " 'agency pricing',\n",
       " 'agenda item',\n",
       " 'agent bank',\n",
       " 'agent general',\n",
       " 'agent noun',\n",
       " 'agent orange',\n",
       " 'agent provocateur',\n",
       " 'agentive role',\n",
       " 'agents general',\n",
       " 'agents provocateurs',\n",
       " 'agglutination test',\n",
       " 'aggravated assault',\n",
       " 'aggravated burglary',\n",
       " 'agnus dei',\n",
       " 'agonic line',\n",
       " 'agonize over',\n",
       " 'agony aunt',\n",
       " 'agony box',\n",
       " 'agony column',\n",
       " 'agony uncle',\n",
       " 'agrarian revolution',\n",
       " 'agree on',\n",
       " 'agree to',\n",
       " 'agree with',\n",
       " 'agreed upon',\n",
       " 'agricultural agent',\n",
       " 'agricultural company',\n",
       " 'agricultural labourer',\n",
       " 'agriculture department',\n",
       " 'aha moment',\n",
       " 'ahead of',\n",
       " 'aid agency',\n",
       " 'aid climbing',\n",
       " 'aid money',\n",
       " 'aid package',\n",
       " 'aid station',\n",
       " 'aid worker',\n",
       " 'aide memoire',\n",
       " 'aided awareness',\n",
       " 'aids baby',\n",
       " 'aids vaccine',\n",
       " 'aids virus',\n",
       " 'aim at',\n",
       " 'aim down',\n",
       " 'aim for',\n",
       " 'aim to',\n",
       " 'aimed at',\n",
       " \"ain't half-bad\",\n",
       " 'aioli sauce',\n",
       " 'air alert',\n",
       " 'air ambulance',\n",
       " 'air attack',\n",
       " 'air bag',\n",
       " 'air ball',\n",
       " 'air base',\n",
       " 'air bed',\n",
       " 'air biscuit',\n",
       " 'air bladder',\n",
       " 'air blower',\n",
       " 'air brake',\n",
       " 'air bridge',\n",
       " 'air bubble',\n",
       " 'air carrier',\n",
       " 'air castle',\n",
       " 'air cell',\n",
       " 'air chamber',\n",
       " 'air cleaner',\n",
       " 'air commodore',\n",
       " 'air compressor',\n",
       " 'air con',\n",
       " 'air conditioned',\n",
       " 'air conditioner',\n",
       " 'air conditioning',\n",
       " 'air cooler',\n",
       " 'air corps',\n",
       " 'air corridor',\n",
       " 'air cover',\n",
       " 'air crew',\n",
       " 'air current',\n",
       " 'air cushion',\n",
       " 'air defense',\n",
       " 'air division',\n",
       " 'air drop',\n",
       " 'air duct',\n",
       " 'air filter',\n",
       " 'air flow',\n",
       " 'air force',\n",
       " 'air freshener',\n",
       " 'air gas',\n",
       " 'air group',\n",
       " 'air guitar',\n",
       " 'air guitarist',\n",
       " 'air gun',\n",
       " 'air hammer',\n",
       " 'air hole',\n",
       " 'air horn',\n",
       " 'air hose',\n",
       " 'air hostess',\n",
       " 'air intake',\n",
       " 'air jacket',\n",
       " 'air kiss',\n",
       " 'air lane',\n",
       " 'air letter',\n",
       " 'air level',\n",
       " 'air lift',\n",
       " 'air lock',\n",
       " 'air mail',\n",
       " 'air marshal',\n",
       " 'air mask',\n",
       " 'air mass',\n",
       " 'air mattress',\n",
       " 'air medal',\n",
       " 'air mile',\n",
       " 'air miles',\n",
       " 'air out',\n",
       " 'air passage',\n",
       " 'air pistol',\n",
       " 'air plant',\n",
       " 'air pocket',\n",
       " 'air pollution',\n",
       " 'air potato',\n",
       " 'air power',\n",
       " 'air pressure',\n",
       " 'air pump',\n",
       " 'air quality',\n",
       " 'air quotes',\n",
       " 'air rage',\n",
       " 'air raid',\n",
       " 'air resistance',\n",
       " 'air ride',\n",
       " 'air rifle',\n",
       " 'air sac',\n",
       " 'air scooter',\n",
       " 'air shaft',\n",
       " 'air shed',\n",
       " 'air show',\n",
       " 'air sick',\n",
       " 'air sickness',\n",
       " 'air sock',\n",
       " 'air space',\n",
       " 'air speed',\n",
       " 'air spring',\n",
       " 'air station',\n",
       " 'air stewardess',\n",
       " 'air stream',\n",
       " 'air strike',\n",
       " 'air support',\n",
       " 'air tank',\n",
       " 'air terminal',\n",
       " 'air time',\n",
       " 'air traffic',\n",
       " 'air transport',\n",
       " 'air travel',\n",
       " 'air traveler',\n",
       " 'air traveller',\n",
       " 'air vent',\n",
       " 'air vice-marshal',\n",
       " 'air wave',\n",
       " 'air waves',\n",
       " 'air well',\n",
       " 'air-raid shelter',\n",
       " 'air-sea rescue',\n",
       " 'air-to-air missile',\n",
       " 'air-to-ground missile',\n",
       " 'air-to-surface missile',\n",
       " 'aircraft attitude',\n",
       " 'aircraft carrier',\n",
       " 'aircraft engine',\n",
       " 'aircraft landing',\n",
       " 'aircraft propeller',\n",
       " 'airedale terrier',\n",
       " 'airing cupboard',\n",
       " 'airline business',\n",
       " 'airline industry',\n",
       " 'airmail letter',\n",
       " 'airplane maneuver',\n",
       " 'airplane pilot',\n",
       " 'airplane propeller',\n",
       " 'airplane ticket',\n",
       " 'airport fiction',\n",
       " 'airport novel',\n",
       " 'airport tax',\n",
       " 'airport terminal',\n",
       " 'airspeed indicator',\n",
       " 'airy beam',\n",
       " 'airy fairy',\n",
       " 'aisle seat',\n",
       " 'al dente',\n",
       " 'al desko',\n",
       " 'al fresco',\n",
       " \"aladdin's cave\",\n",
       " 'alarm bell',\n",
       " 'alarm call',\n",
       " 'alarm clock',\n",
       " 'alarm system',\n",
       " 'albert chain',\n",
       " 'albert hall',\n",
       " 'alcaic verse',\n",
       " 'alcohol abuse',\n",
       " 'alcohol addiction',\n",
       " 'alcohol poisoning',\n",
       " 'alcohol radical',\n",
       " 'alcohol thermometer',\n",
       " 'alcoholic abuse',\n",
       " 'alcoholic beverage',\n",
       " 'alcoholic drink',\n",
       " 'alcoholic drinks',\n",
       " 'alcoholics anonymous',\n",
       " 'aldaric acid',\n",
       " 'alder tree',\n",
       " 'ale drinker',\n",
       " 'ale silver',\n",
       " 'alendronic acid',\n",
       " 'aleutian islands',\n",
       " 'alexander technique',\n",
       " 'alfalfa sprouts',\n",
       " 'algal bloom',\n",
       " 'algarroba bean',\n",
       " 'algebraic number',\n",
       " 'algorithm error',\n",
       " 'ali baba',\n",
       " 'alice band',\n",
       " 'alight on',\n",
       " 'alight upon',\n",
       " 'alignment diagram',\n",
       " 'alimentary canal',\n",
       " 'alimentary tract',\n",
       " 'aliterate person',\n",
       " 'alive with',\n",
       " 'alkali metal',\n",
       " 'alkanium ion',\n",
       " 'alkyl group',\n",
       " 'all aboard',\n",
       " 'all about',\n",
       " 'all agog',\n",
       " 'all along',\n",
       " 'all around',\n",
       " 'all arounder',\n",
       " 'all better',\n",
       " 'all blacks',\n",
       " 'all but',\n",
       " 'all caps',\n",
       " 'all clear',\n",
       " 'all comers',\n",
       " 'all correct',\n",
       " 'all downhill',\n",
       " 'all ears',\n",
       " 'all eyes',\n",
       " 'all for',\n",
       " 'all fours',\n",
       " 'all get-out',\n",
       " 'all gone',\n",
       " 'all holiday',\n",
       " 'all hollow',\n",
       " 'all important',\n",
       " 'all in',\n",
       " 'all inclusive',\n",
       " 'all nations',\n",
       " 'all out',\n",
       " 'all over',\n",
       " 'all right',\n",
       " 'all round',\n",
       " 'all set',\n",
       " 'all show',\n",
       " 'all that',\n",
       " 'all thumbs',\n",
       " 'all together',\n",
       " 'all told',\n",
       " 'all too',\n",
       " 'all wet',\n",
       " \"all y'all\",\n",
       " \"all y'all's\",\n",
       " 'all-day sucker',\n",
       " 'all-in wrestling',\n",
       " 'all-ordinaries index',\n",
       " 'all-over oneself',\n",
       " 'all-points bulletin',\n",
       " 'all-purpose flour',\n",
       " 'all-singing all-dancing',\n",
       " 'all-star game',\n",
       " 'all-terrain bike',\n",
       " 'all-terrain board',\n",
       " 'all-terrain vehicle',\n",
       " 'all-wheel drive',\n",
       " 'alla marcia',\n",
       " 'allan-herndon-dudley syndrome',\n",
       " 'allemande sauce',\n",
       " 'allen ginsberg',\n",
       " 'allen key',\n",
       " 'allen screw',\n",
       " 'allen wrench',\n",
       " 'allergic reaction',\n",
       " 'alley cat',\n",
       " 'alley oop',\n",
       " 'alligator clip',\n",
       " 'alligator pear',\n",
       " 'alligator snapper',\n",
       " 'alligator wrench',\n",
       " 'allocation unit',\n",
       " 'allow for',\n",
       " 'allow in',\n",
       " 'allow of',\n",
       " 'alloy iron',\n",
       " 'alloy steel',\n",
       " 'alloying element',\n",
       " 'allude to',\n",
       " 'alluvial cone',\n",
       " 'alluvial deposit',\n",
       " 'alluvial fan',\n",
       " 'alluvial plain',\n",
       " 'alluvial sediment',\n",
       " 'alluvial soil',\n",
       " 'ally with',\n",
       " 'allyl group',\n",
       " 'allyl isothiocyanate',\n",
       " 'alma mater',\n",
       " 'almighty dollar',\n",
       " 'almond cake',\n",
       " 'almond cookie',\n",
       " 'almond extract',\n",
       " 'almond milk',\n",
       " 'almond oil',\n",
       " 'almond paste',\n",
       " 'almond tree',\n",
       " 'alms box',\n",
       " 'alms dish',\n",
       " 'alms tray',\n",
       " 'aloe vera',\n",
       " 'aloha shirt',\n",
       " 'along about',\n",
       " 'along with',\n",
       " 'aloo gosht',\n",
       " 'alpha blocker',\n",
       " 'alpha brass',\n",
       " 'alpha cen',\n",
       " 'alpha geek',\n",
       " 'alpha male',\n",
       " 'alpha mom',\n",
       " 'alpha particle',\n",
       " 'alpha ray',\n",
       " 'alpha rays',\n",
       " 'alpha receptor',\n",
       " 'alpha test',\n",
       " 'alpha version',\n",
       " 'alpha wave',\n",
       " 'alphabet soup',\n",
       " 'alphabetic character',\n",
       " 'alphabetic writing',\n",
       " 'alphabetical order',\n",
       " 'alphanumeric display',\n",
       " 'alpine ash',\n",
       " 'alpine hat',\n",
       " 'alpine lift',\n",
       " 'alpine plant',\n",
       " 'alpine sunflower',\n",
       " 'alt key',\n",
       " 'altar boy',\n",
       " 'altar cloth',\n",
       " 'altar screen',\n",
       " 'altar wine',\n",
       " 'alter ego',\n",
       " 'alternate angle',\n",
       " 'alternate universe',\n",
       " 'alternating current',\n",
       " 'alternating function',\n",
       " 'alternative birthing',\n",
       " 'alternative country',\n",
       " 'alternative fuel',\n",
       " 'alternative hypothesis',\n",
       " 'alternative lifestyle',\n",
       " 'alternative medicine',\n",
       " 'altitude sickness',\n",
       " 'alto clef',\n",
       " 'alto saxophone',\n",
       " 'aluminium bronze',\n",
       " 'aluminium foil',\n",
       " 'aluminium oxide',\n",
       " 'aluminum foil',\n",
       " 'aluminum shower',\n",
       " 'aluminum smelter',\n",
       " 'alveolar bone',\n",
       " 'alveolar consonant',\n",
       " 'alveolar ridge',\n",
       " 'alzheimer disease',\n",
       " \"alzheimer's disease\",\n",
       " 'amateur dramatic',\n",
       " 'amateur dramatics',\n",
       " 'amateur hour',\n",
       " 'amateur photographer',\n",
       " 'amazon lily',\n",
       " 'amazon river',\n",
       " 'amber alert',\n",
       " 'amber fluid',\n",
       " 'amber gambler',\n",
       " 'amber liquid',\n",
       " 'amber nectar',\n",
       " 'ambient music',\n",
       " 'amble along',\n",
       " 'amble off',\n",
       " 'ambreic acid',\n",
       " 'ambulance chaser',\n",
       " 'ambulatory plague',\n",
       " 'ambush marketing',\n",
       " 'amebic dysentery',\n",
       " 'amen corner',\n",
       " 'amen curler',\n",
       " 'amended return',\n",
       " \"america's cup\",\n",
       " 'american aloe',\n",
       " 'american bison',\n",
       " 'american breakfast',\n",
       " 'american cheese',\n",
       " 'american creeper',\n",
       " 'american cress',\n",
       " 'american dream',\n",
       " 'american eagle',\n",
       " 'american egret',\n",
       " 'american elk',\n",
       " 'american elm',\n",
       " 'american english',\n",
       " 'american express',\n",
       " 'american flag',\n",
       " 'american football',\n",
       " 'american hazel',\n",
       " 'american hop',\n",
       " 'american indian',\n",
       " 'american league',\n",
       " 'american legion',\n",
       " 'american lobster',\n",
       " 'american parasol',\n",
       " 'american plan',\n",
       " 'american rattlebox',\n",
       " 'american revolution',\n",
       " 'american spanish',\n",
       " 'american thanksgiving',\n",
       " 'american way',\n",
       " 'amine scrubber',\n",
       " 'amine ylide',\n",
       " 'amino acid',\n",
       " 'amino aldehyde',\n",
       " 'amino group',\n",
       " 'aminomethylbenzoic acid',\n",
       " 'ammonia clock',\n",
       " 'ammonia water',\n",
       " 'ammonium hydroxide',\n",
       " 'ammonium ion',\n",
       " 'ammonium sulfate',\n",
       " 'ammunition chest',\n",
       " 'amnesty international',\n",
       " 'amniotic cavity',\n",
       " 'amniotic fluid',\n",
       " 'amoebic dysentery',\n",
       " 'amount to',\n",
       " 'amour propre',\n",
       " 'amped up',\n",
       " 'amphibian family',\n",
       " 'amphibious aircraft',\n",
       " 'amphibious car',\n",
       " 'amphibious vehicle',\n",
       " 'amplifier glass',\n",
       " 'amplitude distortion',\n",
       " 'amplitude level',\n",
       " 'amplitude modulation',\n",
       " 'amur leopard',\n",
       " 'amusement arcade',\n",
       " 'amusement park',\n",
       " 'amyl nitrate',\n",
       " 'amyloid plaque',\n",
       " 'anabolic steroid',\n",
       " 'anaerobic respiration',\n",
       " 'anal intercourse',\n",
       " 'anal retentive',\n",
       " 'anal sex',\n",
       " 'anal sphincter',\n",
       " 'anally retentive',\n",
       " 'analog clock',\n",
       " 'analog computer',\n",
       " 'analog hole',\n",
       " 'analog signal',\n",
       " 'analog watch',\n",
       " 'analyst programmer',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = Fetcher(this_corpus.corpus_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.create_bigram_query(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.allocate_filtered_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ug_1</th>\n",
       "      <th>ug_2</th>\n",
       "      <th>token_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>a</td>\n",
       "      <td>124760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there</td>\n",
       "      <td>is</td>\n",
       "      <td>57158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>same</td>\n",
       "      <td>55861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>out</td>\n",
       "      <td>of</td>\n",
       "      <td>47463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have</td>\n",
       "      <td>to</td>\n",
       "      <td>42749.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47481</th>\n",
       "      <td>x-ray</td>\n",
       "      <td>photography</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47482</th>\n",
       "      <td>yellow</td>\n",
       "      <td>cake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47483</th>\n",
       "      <td>yellow</td>\n",
       "      <td>jack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47484</th>\n",
       "      <td>yeoman's</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47485</th>\n",
       "      <td>zanzibar</td>\n",
       "      <td>copal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47486 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ug_1         ug_2  token_freq\n",
       "0            of            a    124760.0\n",
       "1         there           is     57158.0\n",
       "2           the         same     55861.0\n",
       "3           out           of     47463.0\n",
       "4          have           to     42749.0\n",
       "...         ...          ...         ...\n",
       "47481     x-ray  photography         NaN\n",
       "47482    yellow         cake         NaN\n",
       "47483    yellow         jack         NaN\n",
       "47484  yeoman's      service         NaN\n",
       "47485  zanzibar        copal         NaN\n",
       "\n",
       "[47486 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.conn.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE token_freq AS\n",
    "    SELECT \n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        total_freq AS token_freq\n",
    "    FROM filtered_db_total\n",
    "    RIGHT JOIN this_query\n",
    "    USING(ug_1, ug_2)\n",
    "\"\"\")\n",
    "helper(\"SELECT * FROM token_freq ORDER BY token_freq DESC\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE ignore_ngrams AS\n",
    "    SELECT * \n",
    "    FROM token_freq \n",
    "    WHERE token_freq IS NOT DISTINCT FROM NULL\n",
    "\"\"\")\n",
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE reduced_query AS\n",
    "    SELECT * \n",
    "    FROM this_query\n",
    "    ANTI JOIN ignore_ngrams\n",
    "    USING(ug_1, ug_2)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE token_freq AS\n",
    "    SELECT *\n",
    "    FROM token_freq\n",
    "    SEMI JOIN reduced_query\n",
    "    USING(ug_1, ug_2)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"\"\"\n",
    "    CREATE OR REPLACE TABLE type_1 AS\n",
    "    SELECT \n",
    "        ug_2,\n",
    "        COUNT( * ) AS typef_1\n",
    "    FROM filtered_db_total\n",
    "    WHERE ug_2 IN (SELECT ug_2 FROM reduced_query)\n",
    "    GROUP BY\n",
    "        ug_2\n",
    "\"\"\")\n",
    "helper(\"\"\"\n",
    "    CREATE OR REPLACE TABLE type_2 AS\n",
    "    SELECT \n",
    "        ug_1,\n",
    "        COUNT( * ) AS typef_2\n",
    "    FROM filtered_db_total\n",
    "    WHERE ug_1 IN (SELECT ug_1 FROM reduced_query)\n",
    "    GROUP BY\n",
    "        ug_1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ug_1</th>\n",
       "      <th>ug_2</th>\n",
       "      <th>typef_1</th>\n",
       "      <th>typef_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>above</td>\n",
       "      <td>4524</td>\n",
       "      <td>150958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>bends</td>\n",
       "      <td>136</td>\n",
       "      <td>150958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>bomb</td>\n",
       "      <td>462</td>\n",
       "      <td>150958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>burbs</td>\n",
       "      <td>1</td>\n",
       "      <td>150958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>can</td>\n",
       "      <td>17937</td>\n",
       "      <td>150958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31768</th>\n",
       "      <td>uric</td>\n",
       "      <td>acid</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31769</th>\n",
       "      <td>venae</td>\n",
       "      <td>cavae</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31770</th>\n",
       "      <td>verd</td>\n",
       "      <td>antique</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31771</th>\n",
       "      <td>wishy</td>\n",
       "      <td>washy</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31772</th>\n",
       "      <td>yoo</td>\n",
       "      <td>hoo</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31773 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ug_1     ug_2  typef_1  typef_2\n",
       "0        the    above     4524   150958\n",
       "1        the    bends      136   150958\n",
       "2        the     bomb      462   150958\n",
       "3        the    burbs        1   150958\n",
       "4        the      can    17937   150958\n",
       "...      ...      ...      ...      ...\n",
       "31768   uric     acid      827        1\n",
       "31769  venae    cavae        1        1\n",
       "31770   verd  antique      239        1\n",
       "31771  wishy    washy        7        1\n",
       "31772    yoo      hoo       30        1\n",
       "\n",
       "[31773 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE type_freq AS\n",
    "    WITH temp_1 AS (\n",
    "        SELECT *\n",
    "        FROM reduced_query\n",
    "        LEFT JOIN type_1\n",
    "        USING (ug_2)\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM temp_1\n",
    "    LEFT JOIN type_2\n",
    "    USING (ug_1)\n",
    "\"\"\")\n",
    "helper(\"SELECT * FROM type_freq ORDER BY typef_2 DESC\").fetch_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"\"\"\n",
    "CREATE OR REPLACE TABLE corpus_ngram_combs AS \n",
    "    SELECT corpus, ug_1, ug_2\n",
    "    FROM (SELECT DISTINCT ug_1, ug_2 FROM filtered_db)\n",
    "    SEMI JOIN reduced_query\n",
    "    USING(ug_1, ug_2)\n",
    "    CROSS JOIN (SELECT DISTINCT corpus FROM filtered_db)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"\"\"\n",
    "    CREATE OR REPLACE TABLE disp_table AS\n",
    "    SELECT corpus, ug_1, ug_2, COALESCE(freq, 0) as freq\n",
    "    FROM corpus_ngram_combs\n",
    "    LEFT JOIN filtered_db\n",
    "    USING(corpus, ug_1, ug_2)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE disp_table AS\n",
    "    SELECT *\n",
    "    FROM disp_table \n",
    "    LEFT JOIN corpus_proportions\n",
    "    USING(corpus)\n",
    "    WHERE ug_1 IN (SELECT ug_1 FROM this_query) AND ug_2 IN (SELECT ug_2 FROM this_query)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE disp_table AS\n",
    "    SELECT \n",
    "        corpus,\n",
    "        disp_table.ug_1,\n",
    "        disp_table.ug_2,\n",
    "        freq / total_freq AS proportion,\n",
    "        corpus_prop\n",
    "    FROM disp_table\n",
    "    LEFT JOIN filtered_db_total\n",
    "    USING(ug_1, ug_2)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE dispersion AS\n",
    "    WITH kld_table AS (SELECT \n",
    "        corpus,\n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        CASE\n",
    "            WHEN proportion > 0 THEN proportion * log2(proportion / corpus_prop)\n",
    "            ELSE 0\n",
    "        END AS KLD\n",
    "    FROM disp_table\n",
    "    )\n",
    "    SELECT \n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        1 - pow(EXP(1), -SUM(KLD)) as dispersion\n",
    "    FROM kld_table\n",
    "    GROUP BY (ug_1, ug_2)\n",
    "    ORDER BY dispersion\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associations @_@ Heavy use of CTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE unigram_totals AS\n",
    "    SELECT \n",
    "        ug,\n",
    "        SUM(freq) AS freq,\n",
    "        SUM(SUM(freq)) OVER () AS total_ug,\n",
    "    FROM unigram_db\n",
    "    GROUP BY (ug)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE rel_freqs AS\n",
    "    SELECT \n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        token_freq,\n",
    "        unigram_totals.freq AS ug_1_freq,\n",
    "        unigram_totals.total_ug \n",
    "    FROM token_freq\n",
    "    LEFT JOIN unigram_totals\n",
    "    ON token_freq.ug_1 = unigram_totals.ug\n",
    "    \"\"\")\n",
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE rel_freqs AS\n",
    "    SELECT \n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        token_freq,\n",
    "        ug_1_freq,\n",
    "        unigram_totals.freq AS ug_2_freq,\n",
    "        rel_freqs.total_ug\n",
    "    FROM rel_freqs\n",
    "    LEFT JOIN unigram_totals\n",
    "    ON rel_freqs.ug_2 = unigram_totals.ug\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"\"\"\n",
    "    CREATE OR REPLACE TABLE associations AS\n",
    "    WITH probs_db AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            ug_2, \n",
    "            token_freq / ug_1_freq AS prob_2_1,\n",
    "            token_freq / ug_2_freq AS prob_1_2,\n",
    "            ug_1_freq / total_ug AS prob_1,\n",
    "            ug_2_freq / total_ug AS prob_2\n",
    "        FROM rel_freqs\n",
    "    ), all_probs AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            ug_2,\n",
    "            prob_2_1,\n",
    "            prob_1_2,\n",
    "            prob_1,\n",
    "            prob_2,\n",
    "            1 - prob_2_1 AS prob_no_2_1,\n",
    "            1 - prob_1_2 AS prob_no_1_2,\n",
    "            1 - prob_1 AS prob_no_1,\n",
    "            1 - prob_2 AS prob_no_2\n",
    "        FROM probs_db\n",
    "    ), forward_kld AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            ug_2,\n",
    "            prob_2_1 * log2(prob_2_1 / prob_2) AS kld_1,\n",
    "            CASE\n",
    "                WHEN prob_no_2_1 = 0 THEN 0\n",
    "                ELSE (1 - prob_2_1) * log2((1 - prob_2_1) / (1 - prob_2))\n",
    "            END AS kld_2\n",
    "        FROM all_probs\n",
    "    ), forward_assoc AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            ug_2,\n",
    "            1 - pow(EXP(1), -(kld_1 + kld_2)) AS fw_assoc\n",
    "        FROM forward_kld\n",
    "    ), backward_kld AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            ug_2,\n",
    "            prob_1_2 * log2(prob_1_2 / prob_1) AS kld_1,\n",
    "            CASE\n",
    "                WHEN prob_no_1_2 = 0 THEN 0\n",
    "                ELSE (1 - prob_1_2) * log2((1 - prob_1_2) / (1 - prob_1))\n",
    "            END AS kld_2\n",
    "        FROM all_probs\n",
    "    ), backward_assoc AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            ug_2,\n",
    "            1 - pow(EXP(1), -(kld_1 + kld_2)) AS bw_assoc\n",
    "        FROM backward_kld\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM forward_assoc\n",
    "    LEFT JOIN backward_assoc\n",
    "    USING(ug_1, ug_2)\n",
    "    ORDER BY bw_assoc DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ug_1</th>\n",
       "      <th>ug_2</th>\n",
       "      <th>fw_assoc</th>\n",
       "      <th>bw_assoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>venae</td>\n",
       "      <td>cavae</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mirabile</td>\n",
       "      <td>dictu</td>\n",
       "      <td>9.999953e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>higgledy</td>\n",
       "      <td>piggledy</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hapax</td>\n",
       "      <td>legomenon</td>\n",
       "      <td>9.996402e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petitio</td>\n",
       "      <td>principii</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31770</th>\n",
       "      <td>kill</td>\n",
       "      <td>for</td>\n",
       "      <td>7.087886e-09</td>\n",
       "      <td>3.563361e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31771</th>\n",
       "      <td>drive</td>\n",
       "      <td>in</td>\n",
       "      <td>7.757663e-09</td>\n",
       "      <td>3.449629e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31772</th>\n",
       "      <td>shy</td>\n",
       "      <td>from</td>\n",
       "      <td>1.038004e-08</td>\n",
       "      <td>2.792855e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31773</th>\n",
       "      <td>tool</td>\n",
       "      <td>case</td>\n",
       "      <td>1.668109e-10</td>\n",
       "      <td>8.026579e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31774</th>\n",
       "      <td>heel</td>\n",
       "      <td>over</td>\n",
       "      <td>5.374559e-10</td>\n",
       "      <td>3.094858e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31775 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ug_1       ug_2      fw_assoc      bw_assoc\n",
       "0         venae      cavae  1.000000e+00  1.000000e+00\n",
       "1      mirabile      dictu  9.999953e-01  1.000000e+00\n",
       "2      higgledy   piggledy  1.000000e+00  1.000000e+00\n",
       "3         hapax  legomenon  9.996402e-01  1.000000e+00\n",
       "4       petitio  principii  9.999999e-01  1.000000e+00\n",
       "...         ...        ...           ...           ...\n",
       "31770      kill        for  7.087886e-09  3.563361e-11\n",
       "31771     drive         in  7.757663e-09  3.449629e-11\n",
       "31772       shy       from  1.038004e-08  2.792855e-11\n",
       "31773      tool       case  1.668109e-10  8.026579e-12\n",
       "31774      heel       over  5.374559e-10  3.094858e-12\n",
       "\n",
       "[31775 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"SELECT * FROM associations\").fetch_df()\n",
    "# Now it's good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slot 2\n",
    "# Real entropy\n",
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE entropy_real_2 AS\n",
    "    WITH all_freqs AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM filtered_db_total\n",
    "        WHERE ug_1 IN (SELECT ug_1 FROM reduced_query)\n",
    "    ), ug_1_freqs AS (\n",
    "        SELECT *\n",
    "        FROM reduced_query\n",
    "        LEFT JOIN all_freqs\n",
    "        USING(ug_1)\n",
    "    ), freqs AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            ug_2 AS target,\n",
    "            ug_2_1 AS ug_2,\n",
    "            total_freq\n",
    "        FROM ug_1_freqs\n",
    "    ), totals AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            SUM(total_freq) AS total\n",
    "        FROM freqs\n",
    "        GROUP BY ug_1\n",
    "    ), probs AS (\n",
    "        SELECT \n",
    "            ug_1,\n",
    "            target,\n",
    "            ug_2,\n",
    "            total_freq / total AS prob\n",
    "        FROM freqs\n",
    "        LEFT JOIN totals\n",
    "        USING(ug_1)\n",
    "    ), info AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            target,\n",
    "            CASE\n",
    "                WHEN prob > 0 THEN prob * log2(prob)\n",
    "                ELSE 0\n",
    "            END AS info\n",
    "        FROM probs\n",
    "    ), entropy AS (\n",
    "        SELECT \n",
    "            ug_1,\n",
    "            target AS ug_2,\n",
    "            SUM(CASE WHEN info < 0 THEN -info ELSE 0 END) AS entropy,\n",
    "            log2(COUNT (*)) AS normalizer\n",
    "        FROM info\n",
    "        GROUP BY ug_1, target\n",
    "    )\n",
    "    SELECT\n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        CASE\n",
    "            WHEN normalizer > 0 THEN entropy / normalizer\n",
    "            ELSE 0\n",
    "        END as entropy_real\n",
    "    FROM entropy\n",
    "    ORDER BY entropy_real DESC\n",
    "\"\"\")\n",
    "\n",
    "# Counterfactual entropy\n",
    "\n",
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE entropy_cf_2 AS\n",
    "    WITH all_freqs AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM filtered_db_total\n",
    "        WHERE ug_1 IN (SELECT ug_1 FROM reduced_query)\n",
    "    ), ug_1_freqs AS (\n",
    "        SELECT *\n",
    "        FROM reduced_query\n",
    "        LEFT JOIN all_freqs\n",
    "        USING(ug_1)\n",
    "    ), freqs AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            ug_2 AS target,\n",
    "            ug_2_1 AS ug_2,\n",
    "            CASE\n",
    "                WHEN ug_2 = ug_2_1 THEN 0\n",
    "                ELSE total_freq\n",
    "            END AS total_freq\n",
    "        FROM ug_1_freqs\n",
    "    ), totals AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            SUM(total_freq) AS total\n",
    "        FROM freqs\n",
    "        GROUP BY ug_1\n",
    "    ), probs AS (\n",
    "        SELECT \n",
    "            ug_1,\n",
    "            target,\n",
    "            ug_2,\n",
    "            total_freq / total AS prob\n",
    "        FROM freqs\n",
    "        LEFT JOIN totals\n",
    "        USING(ug_1)\n",
    "    ), info AS (\n",
    "        SELECT\n",
    "            ug_1,\n",
    "            target,\n",
    "            CASE\n",
    "                WHEN prob > 0 THEN prob * log2(prob)\n",
    "                ELSE 0\n",
    "            END AS info\n",
    "        FROM probs\n",
    "        WHERE target != ug_2\n",
    "    ), entropy AS (\n",
    "        SELECT \n",
    "            ug_1,\n",
    "            target AS ug_2,\n",
    "            SUM(CASE WHEN info < 0 THEN -info ELSE 0 END) AS entropy,\n",
    "            log2(COUNT (*)) AS normalizer\n",
    "        FROM info\n",
    "        GROUP BY ug_1, target\n",
    "    )\n",
    "    SELECT\n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        CASE\n",
    "            WHEN normalizer > 0 THEN entropy / normalizer\n",
    "            ELSE 0\n",
    "        END as entropy_cf\n",
    "    FROM entropy\n",
    "    ORDER BY entropy_cf DESC\n",
    "\"\"\")\n",
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE entropy_2 AS\n",
    "    SELECT \n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        entropy_cf - entropy_real AS entropy_2\n",
    "    FROM entropy_real_2\n",
    "    INNER JOIN entropy_cf_2\n",
    "    USING(ug_1, ug_2)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slot 1\n",
    "# Why is this stratospherically slower than slot 2?????? is it because \"the\"??\n",
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE entropy_real_1 AS\n",
    "    WITH all_freqs AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM filtered_db_total\n",
    "        WHERE ug_2 IN (SELECT ug_2 FROM reduced_query)\n",
    "    ), ug_2_freqs AS (\n",
    "        SELECT *\n",
    "        FROM reduced_query\n",
    "        LEFT JOIN all_freqs\n",
    "        USING(ug_2)\n",
    "    ), freqs AS (\n",
    "        SELECT\n",
    "            ug_2,\n",
    "            ug_1 AS target,\n",
    "            ug_1_1 AS ug_1,\n",
    "            total_freq\n",
    "        FROM ug_2_freqs\n",
    "    ), totals AS (\n",
    "        SELECT\n",
    "            ug_2,\n",
    "            SUM(total_freq) AS total\n",
    "        FROM freqs\n",
    "        GROUP BY ug_2\n",
    "    ), probs AS (\n",
    "        SELECT \n",
    "            ug_2,\n",
    "            target,\n",
    "            ug_1,\n",
    "            total_freq / total AS prob\n",
    "        FROM freqs\n",
    "        LEFT JOIN totals\n",
    "        USING(ug_2)\n",
    "    ), info AS (\n",
    "        SELECT\n",
    "            ug_2,\n",
    "            target,\n",
    "            CASE\n",
    "                WHEN prob > 0 THEN prob * log2(prob)\n",
    "                ELSE 0\n",
    "            END AS info\n",
    "        FROM probs\n",
    "    ), entropy AS (\n",
    "        SELECT \n",
    "            ug_2,\n",
    "            target AS ug_1,\n",
    "            SUM(CASE WHEN info < 0 THEN -info ELSE 0 END) AS entropy,\n",
    "            log2(COUNT (*)) AS normalizer\n",
    "        FROM info\n",
    "        GROUP BY ug_2, target\n",
    "    )\n",
    "    SELECT\n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        CASE\n",
    "            WHEN normalizer > 0 THEN entropy / normalizer\n",
    "            ELSE 0\n",
    "        END as entropy_real\n",
    "    FROM entropy\n",
    "    ORDER BY entropy_real DESC\n",
    "\"\"\")\n",
    "\n",
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE entropy_cf_1 AS\n",
    "    WITH all_freqs AS (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM filtered_db_total\n",
    "        WHERE ug_2 IN (SELECT ug_2 FROM reduced_query)\n",
    "    ), ug_2_freqs AS (\n",
    "        SELECT *\n",
    "        FROM reduced_query\n",
    "        LEFT JOIN all_freqs\n",
    "        USING(ug_2)\n",
    "    ), freqs AS (\n",
    "        SELECT\n",
    "            ug_2,\n",
    "            ug_1 AS target,\n",
    "            ug_1_1 AS ug_1,\n",
    "            CASE\n",
    "                WHEN ug_1 = ug_1_1 THEN 0\n",
    "                ELSE total_freq\n",
    "            END AS total_freq\n",
    "        FROM ug_2_freqs\n",
    "    ), totals AS (\n",
    "        SELECT\n",
    "            ug_2,\n",
    "            SUM(total_freq) AS total\n",
    "        FROM freqs\n",
    "        GROUP BY ug_2\n",
    "    ), probs AS (\n",
    "        SELECT \n",
    "            ug_2,\n",
    "            target,\n",
    "            ug_1,\n",
    "            total_freq / total AS prob\n",
    "        FROM freqs\n",
    "        LEFT JOIN totals\n",
    "        USING(ug_2)\n",
    "    ), info AS (\n",
    "        SELECT\n",
    "            ug_2,\n",
    "            target,\n",
    "            CASE\n",
    "                WHEN prob > 0 THEN prob * log2(prob)\n",
    "                ELSE 0\n",
    "            END AS info\n",
    "        FROM probs\n",
    "        WHERE target != ug_1\n",
    "    ), entropy AS (\n",
    "        SELECT \n",
    "            ug_2,\n",
    "            target AS ug_1,\n",
    "            SUM(CASE WHEN info < 0 THEN -info ELSE 0 END) AS entropy,\n",
    "            log2(COUNT (*)) AS normalizer\n",
    "        FROM info\n",
    "        GROUP BY ug_2, target\n",
    "    )\n",
    "    SELECT\n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        CASE\n",
    "            WHEN normalizer > 0 THEN entropy / normalizer\n",
    "            ELSE 0\n",
    "        END as entropy_cf\n",
    "    FROM entropy\n",
    "    ORDER BY entropy_cf DESC\n",
    "\"\"\")\n",
    "\n",
    "helper(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE entropy_1 AS\n",
    "    SELECT \n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        entropy_cf - entropy_real AS entropy_1\n",
    "    FROM entropy_real_1\n",
    "    INNER JOIN entropy_cf_1\n",
    "    USING(ug_1, ug_2)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now it's good\n",
    "helper(\"\"\"\n",
    "       CREATE OR REPLACE TABLE entropy_diffs AS\n",
    "       SELECT * FROM entropy_1\n",
    "       INNER JOIN entropy_2\n",
    "       USING(ug_1, ug_2)\n",
    "       \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"\"\"\n",
    "       CREATE OR REPLACE TABLE raw_measures AS\n",
    "       SELECT \n",
    "              *,\n",
    "              2 AS ngram_length\n",
    "       FROM reduced_query\n",
    "       INNER JOIN token_freq USING(ug_1, ug_2)\n",
    "       INNER JOIN dispersion USING(ug_1, ug_2)\n",
    "       INNER JOIN type_freq USING (ug_1, ug_2)\n",
    "       INNER JOIN entropy_diffs USING (ug_1, ug_2)\n",
    "       INNER JOIN associations USING(ug_1, ug_2)\n",
    "       \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ug_1</th>\n",
       "      <th>ug_2</th>\n",
       "      <th>token_freq</th>\n",
       "      <th>dispersion</th>\n",
       "      <th>typef_1</th>\n",
       "      <th>typef_2</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_2</th>\n",
       "      <th>fw_assoc</th>\n",
       "      <th>bw_assoc</th>\n",
       "      <th>ngram_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st</td>\n",
       "      <td>class</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.732644</td>\n",
       "      <td>2005</td>\n",
       "      <td>270</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>5.776097e-02</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>battery</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.044579</td>\n",
       "      <td>313</td>\n",
       "      <td>71512</td>\n",
       "      <td>-0.014431</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.545372e-04</td>\n",
       "      <td>0.242534</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>bit</td>\n",
       "      <td>16432.0</td>\n",
       "      <td>0.220602</td>\n",
       "      <td>1106</td>\n",
       "      <td>71512</td>\n",
       "      <td>-0.023982</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>2.565659e-02</td>\n",
       "      <td>0.915398</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>bunch</td>\n",
       "      <td>586.0</td>\n",
       "      <td>0.119691</td>\n",
       "      <td>225</td>\n",
       "      <td>71512</td>\n",
       "      <td>0.011449</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>8.382538e-04</td>\n",
       "      <td>0.821681</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>capella</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.940355</td>\n",
       "      <td>22</td>\n",
       "      <td>71512</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>3.825570e-07</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31582</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31583</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31585</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31586</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31587 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ug_1     ug_2  token_freq  dispersion  typef_1  typef_2  entropy_1  \\\n",
       "0       1st    class        16.0    0.732644     2005      270   0.000278   \n",
       "1         a  battery       206.0    0.044579      313    71512  -0.014431   \n",
       "2         a      bit     16432.0    0.220602     1106    71512  -0.023982   \n",
       "3         a    bunch       586.0    0.119691      225    71512   0.011449   \n",
       "4         a  capella         2.0    0.940355       22    71512   0.001896   \n",
       "...     ...      ...         ...         ...      ...      ...        ...   \n",
       "31582  sans    serif        11.0    0.886609       10       52   0.023451   \n",
       "31583  sans    serif        11.0    0.886609       10       52   0.023451   \n",
       "31584  sans    serif        11.0    0.886609       10       52   0.023451   \n",
       "31585  sans    serif        11.0    0.886609       10       52   0.023451   \n",
       "31586  sans    serif        11.0    0.886609       10       52   0.023451   \n",
       "\n",
       "       entropy_2      fw_assoc  bw_assoc  ngram_length  \n",
       "0      -0.000988  5.776097e-02  0.004185             2  \n",
       "1       0.000034  1.545372e-04  0.242534             2  \n",
       "2      -0.000101  2.565659e-02  0.915398             2  \n",
       "3       0.000030  8.382538e-04  0.821681             2  \n",
       "4       0.000036  3.825570e-07  0.022242             2  \n",
       "...          ...           ...       ...           ...  \n",
       "31582   0.022138  8.054401e-01  0.989773             2  \n",
       "31583   0.022138  8.054401e-01  0.989773             2  \n",
       "31584   0.022138  8.054401e-01  0.989773             2  \n",
       "31585   0.022138  8.054401e-01  0.989773             2  \n",
       "31586   0.022138  8.054401e-01  0.989773             2  \n",
       "\n",
       "[31587 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"SELECT * FROM raw_measures\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f2cff0116f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_limits = [-0.1, 0.1]\n",
    "helper(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE normalized_measures AS\n",
    "    SELECT\n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        (log(token_freq) - log(1)) / (log(ngram_totals.max_token) - log(1)) AS token_freq,\n",
    "        1 - dispersion AS dispersion,\n",
    "        (log(typef_1) - log(1)) / (log(ngram_totals.max_type1) - log(1)) AS type_1,\n",
    "        (log(typef_2) - log(1)) / (log(ngram_totals.max_type2) - log(1)) AS type_2,\n",
    "        CASE\n",
    "            WHEN entropy_1 < {entropy_limits[0]} THEN 0\n",
    "            WHEN entropy_1 > {entropy_limits[1]} THEN 1\n",
    "            ELSE (entropy_1 - {entropy_limits[0]}) / ({entropy_limits[1]} - {entropy_limits[0]})\n",
    "        END AS entropy_1,\n",
    "        CASE\n",
    "            WHEN entropy_2 < {entropy_limits[0]} THEN 0\n",
    "            WHEN entropy_2 > {entropy_limits[1]} THEN 1\n",
    "            ELSE (entropy_2 - {entropy_limits[0]}) / ({entropy_limits[1]} - {entropy_limits[0]})\n",
    "        END AS entropy_2,\n",
    "        fw_assoc,\n",
    "        bw_assoc\n",
    "    FROM raw_measures\n",
    "    LEFT JOIN ngram_totals\n",
    "    USING (ngram_length)\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ug_1</th>\n",
       "      <th>ug_2</th>\n",
       "      <th>token_freq</th>\n",
       "      <th>dispersion</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_2</th>\n",
       "      <th>fw_assoc</th>\n",
       "      <th>bw_assoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st</td>\n",
       "      <td>class</td>\n",
       "      <td>0.204767</td>\n",
       "      <td>0.267356</td>\n",
       "      <td>0.645090</td>\n",
       "      <td>0.469479</td>\n",
       "      <td>0.501392</td>\n",
       "      <td>0.495062</td>\n",
       "      <td>5.776097e-02</td>\n",
       "      <td>0.004185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>battery</td>\n",
       "      <td>0.393485</td>\n",
       "      <td>0.955421</td>\n",
       "      <td>0.487521</td>\n",
       "      <td>0.937346</td>\n",
       "      <td>0.427846</td>\n",
       "      <td>0.500169</td>\n",
       "      <td>1.545372e-04</td>\n",
       "      <td>0.242534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>bit</td>\n",
       "      <td>0.716899</td>\n",
       "      <td>0.779398</td>\n",
       "      <td>0.594618</td>\n",
       "      <td>0.937346</td>\n",
       "      <td>0.380091</td>\n",
       "      <td>0.499493</td>\n",
       "      <td>2.565659e-02</td>\n",
       "      <td>0.915398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>bunch</td>\n",
       "      <td>0.470695</td>\n",
       "      <td>0.880309</td>\n",
       "      <td>0.459515</td>\n",
       "      <td>0.937346</td>\n",
       "      <td>0.557245</td>\n",
       "      <td>0.500148</td>\n",
       "      <td>8.382538e-04</td>\n",
       "      <td>0.821681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>capella</td>\n",
       "      <td>0.051192</td>\n",
       "      <td>0.059645</td>\n",
       "      <td>0.262251</td>\n",
       "      <td>0.937346</td>\n",
       "      <td>0.509478</td>\n",
       "      <td>0.500182</td>\n",
       "      <td>3.825570e-07</td>\n",
       "      <td>0.022242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31582</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>0.177094</td>\n",
       "      <td>0.113391</td>\n",
       "      <td>0.195357</td>\n",
       "      <td>0.331348</td>\n",
       "      <td>0.617256</td>\n",
       "      <td>0.610691</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31583</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>0.177094</td>\n",
       "      <td>0.113391</td>\n",
       "      <td>0.195357</td>\n",
       "      <td>0.331348</td>\n",
       "      <td>0.617256</td>\n",
       "      <td>0.610691</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>0.177094</td>\n",
       "      <td>0.113391</td>\n",
       "      <td>0.195357</td>\n",
       "      <td>0.331348</td>\n",
       "      <td>0.617256</td>\n",
       "      <td>0.610691</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31585</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>0.177094</td>\n",
       "      <td>0.113391</td>\n",
       "      <td>0.195357</td>\n",
       "      <td>0.331348</td>\n",
       "      <td>0.617256</td>\n",
       "      <td>0.610691</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31586</th>\n",
       "      <td>sans</td>\n",
       "      <td>serif</td>\n",
       "      <td>0.177094</td>\n",
       "      <td>0.113391</td>\n",
       "      <td>0.195357</td>\n",
       "      <td>0.331348</td>\n",
       "      <td>0.617256</td>\n",
       "      <td>0.610691</td>\n",
       "      <td>8.054401e-01</td>\n",
       "      <td>0.989773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31587 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ug_1     ug_2  token_freq  dispersion    type_1    type_2  entropy_1  \\\n",
       "0       1st    class    0.204767    0.267356  0.645090  0.469479   0.501392   \n",
       "1         a  battery    0.393485    0.955421  0.487521  0.937346   0.427846   \n",
       "2         a      bit    0.716899    0.779398  0.594618  0.937346   0.380091   \n",
       "3         a    bunch    0.470695    0.880309  0.459515  0.937346   0.557245   \n",
       "4         a  capella    0.051192    0.059645  0.262251  0.937346   0.509478   \n",
       "...     ...      ...         ...         ...       ...       ...        ...   \n",
       "31582  sans    serif    0.177094    0.113391  0.195357  0.331348   0.617256   \n",
       "31583  sans    serif    0.177094    0.113391  0.195357  0.331348   0.617256   \n",
       "31584  sans    serif    0.177094    0.113391  0.195357  0.331348   0.617256   \n",
       "31585  sans    serif    0.177094    0.113391  0.195357  0.331348   0.617256   \n",
       "31586  sans    serif    0.177094    0.113391  0.195357  0.331348   0.617256   \n",
       "\n",
       "       entropy_2      fw_assoc  bw_assoc  \n",
       "0       0.495062  5.776097e-02  0.004185  \n",
       "1       0.500169  1.545372e-04  0.242534  \n",
       "2       0.499493  2.565659e-02  0.915398  \n",
       "3       0.500148  8.382538e-04  0.821681  \n",
       "4       0.500182  3.825570e-07  0.022242  \n",
       "...          ...           ...       ...  \n",
       "31582   0.610691  8.054401e-01  0.989773  \n",
       "31583   0.610691  8.054401e-01  0.989773  \n",
       "31584   0.610691  8.054401e-01  0.989773  \n",
       "31585   0.610691  8.054401e-01  0.989773  \n",
       "31586   0.610691  8.054401e-01  0.989773  \n",
       "\n",
       "[31587 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper(\"SELECT * FROM normalized_measures\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ug_1</th>\n",
       "      <th>ug_2</th>\n",
       "      <th>MWU_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rather</td>\n",
       "      <td>than</td>\n",
       "      <td>0.804153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>same</td>\n",
       "      <td>0.793573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>more</td>\n",
       "      <td>than</td>\n",
       "      <td>0.778260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>least</td>\n",
       "      <td>0.777343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>whole</td>\n",
       "      <td>0.769021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31582</th>\n",
       "      <td>frontal</td>\n",
       "      <td>lobotomy</td>\n",
       "      <td>0.150271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31583</th>\n",
       "      <td>ride</td>\n",
       "      <td>horseback</td>\n",
       "      <td>0.150068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584</th>\n",
       "      <td>citrus</td>\n",
       "      <td>medica</td>\n",
       "      <td>0.139243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31585</th>\n",
       "      <td>otitis</td>\n",
       "      <td>externa</td>\n",
       "      <td>0.136719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31586</th>\n",
       "      <td>palo</td>\n",
       "      <td>verde</td>\n",
       "      <td>0.123676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31587 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ug_1       ug_2  MWU_score\n",
       "0       rather       than   0.804153\n",
       "1          the       same   0.793573\n",
       "2         more       than   0.778260\n",
       "3           at      least   0.777343\n",
       "4          the      whole   0.769021\n",
       "...        ...        ...        ...\n",
       "31582  frontal   lobotomy   0.150271\n",
       "31583     ride  horseback   0.150068\n",
       "31584   citrus     medica   0.139243\n",
       "31585   otitis    externa   0.136719\n",
       "31586     palo      verde   0.123676\n",
       "\n",
       "[31587 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dict = {'token_freq': 1/4, 'dispersion': 1/4, 'type_1': 1/8, 'type_2': 1/8, 'entropy_1': 1/16, 'entropy_2': 1/16, 'fw_assoc': 1/16, 'bw_assoc': 1/16}\n",
    "\n",
    "helper(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        ug_1,\n",
    "        ug_2,\n",
    "        {weight_dict['token_freq']} * (token_freq) + \n",
    "        {weight_dict['dispersion']} * (dispersion) + \n",
    "        {weight_dict['type_1']} * type_1 + \n",
    "        {weight_dict['type_2']} * type_2 + \n",
    "        {weight_dict['entropy_1']} * entropy_1 + \n",
    "        {weight_dict['entropy_2']} * entropy_2 + \n",
    "        {weight_dict['fw_assoc']} * fw_assoc + \n",
    "        {weight_dict['bw_assoc']} * bw_assoc \n",
    "        AS MWU_score\n",
    "    FROM normalized_measures\n",
    "    ORDER BY MWU_score DESC\n",
    "\"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: function with (source, target) arguments and f strings\n",
    "# TODO: batches to not crash memory when using complete corpus. Worth it? faster because of the simpler joins? worth it to hash?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwu_measures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
