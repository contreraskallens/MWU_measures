{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwu_measures\n",
    "import pandas as pd\n",
    "import mwu_measures.preprocessing_corpus\n",
    "import mwu_measures.processing_corpus\n",
    "from mwu_measures.corpus_helper import Fetcher\n",
    "from mwu_measures.corpus import Corpus\n",
    "import duckdb\n",
    "from rich.progress import Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mwu_examples = pd.read_csv('MultiwordExpression_Concreteness_Ratings.csv')\n",
    "mwu_examples['length'] = mwu_examples['Expression'].apply(lambda x: len(x.split()))\n",
    "mwu_examples = mwu_examples.loc[(mwu_examples['length'] == 2) | (mwu_examples['length'] == 3)]\n",
    "mwu_examples['Expression'] = mwu_examples['Expression'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mwu_measures.processing_corpus.make_processed_corpus('coca', 'mwu_measures/corpora/coca_texts/', chunk_size=10, verbose=True)\n",
    "# wrapper = lp(mwu_measures.processing_corpus.get_processed_corpus)\n",
    "# this_corpus = mwu_measures.processing_corpus.get_processed_corpus('bnc', 'small_corpus.txt', chunk_size=10000000, verbose=False)\n",
    "# this_corpus = mwu_measures.processing_corpus.make_processed_corpus(test_corpus=True, threshold=0)\n",
    "# lp.print_stats()\n",
    "# ngram_selection = [ngram.split() for ngram in ngram_selection]\n",
    "# ngram_chunks = np.array_split(ngram_selection, 100)\n",
    "bigrams = [['b', 'd'], ['c', 'b'], ['a', 'c']]\n",
    "# helper = Fetcher(this_corpus)\n",
    "# 340 seconds for all _acad_. Not bad, not the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = Corpus(\"test\")\n",
    "helper = Fetcher(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus.create_query(bigrams, 'ug_1', 'ug_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus.get_ngram_scores('ug_1', 'ug_2', 2)['raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_corpus = Corpus(\"coca\")\n",
    "helper = Fetcher(this_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = mwu_examples['Expression'].tolist()\n",
    "# ngrams = [[ngram[0] + ' ' + ngram[1], ngram[2]] if len(ngram) == 3 else ngram for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = helper.get_score_batch(ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x[0][~x[0]['ngram_length'].isna()].drop_duplicates().sort_values(by=['mwu_score'], ascending=False).iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data_1 = pd.read_csv('test.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data_2 = pd.read_csv('train.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data_3 = pd.read_csv('valid.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data = pd.concat([human_data_1, human_data_2, human_data_3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data['utterance'] = human_data['utterance'].str.replace('_comma_', ' , ')\n",
    "human_data['prompt'] = human_data['prompt'].str.replace('_comma_', ' , ')\n",
    "human_data['utterance'] = human_data['utterance'].str.replace('n t ', \"n't \", regex=False)\n",
    "human_data['prompt'] = human_data['prompt'].str.replace('n t ', \"n't \", regex=False)\n",
    "human_data['utterance'] = human_data['utterance'].str.replace(r'n t[$\\.]', \"n't\", regex=True)\n",
    "human_data['prompt'] = human_data['prompt'].str.replace(r'n t[$\\.]', \"n't\", regex=True)\n",
    "# human_data['prompt'] = human_data['prompt'].str.replace('wasnt', \"wasn't\", regex=True)\n",
    "# human_data['utterance'] = human_data['utterance'].str.replace('wasnt', \"wasn't\", regex=True)\n",
    "\n",
    "human_utterances = human_data.utterance.apply(mwu_measures.process_text)\n",
    "human_prompts = human_data.prompt.apply(mwu_measures.process_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text = pd.concat([human_utterances, human_prompts])\n",
    "human_text = human_text.explode()\n",
    "human_text = human_text.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text = human_text.drop_duplicates().dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batches = [human_text.iloc[i*50000:(i+1)*50000].copy() for i in range(int(len(human_text) / 50000) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batches = [batch.to_list() for batch in text_batches]\n",
    "# TODO: does wasn t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = {'token_freq': 1/8, 'dispersion': 1/4, 'type_1': 1/16, 'type_2': 1/8, 'entropy_1': 1/16, 'entropy_2': 1/8, 'fw_assoc': 1/8, 'bw_assoc': 1/16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text_mwu = []\n",
    "i = 0\n",
    "for batch in text_batches:\n",
    "    print((i / len(text_batches)))\n",
    "    human_text_mwu.append(helper.get_score_batch(batch, weights=test_weights, from_text=True))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text_mwu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((result[0] for result in human_text_mwu)).sort_values(by = 'ngram').to_csv('human_mwu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text_mwu.drop_duplicates().sort_values(by=['mwu_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LO HICE!!!\n",
    "this_corpus.create_query(ngrams, 'big_1', 'ug_3')\n",
    "this_corpus.get_ngram_scores('big_1', 'ug_3', 3, [-0.1, 0.1])['normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_corpus.df(\"SELECT * FROM trigram_db WHERE big_1 = HASH('read up') AND ug_3 = HASH('about')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper(\"SELECT DISTINCT * FROM entropy_diffs\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy broken for trigrams again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = helper.get_score_batch(mwu_examples['Expression']).sort_values(by='mwu_score')\n",
    "x[x['ngram_length'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper(\"SELECT * FROM raw_measures\", df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = ['come in handy', 'family friend', 'database management system', 'one hundred percent', 'line of control', 'like a', 'boiled potatoes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = helper\n",
    "normalized=True\n",
    "# self.get_score_batch(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Hello! Come in and eat boiled potatoes they are one hundred percent good.\\nI remember when we met in the year 2000'\n",
    "sentence = mwu_measures.process_text(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.create_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_score_batch(sentence)\n",
    "# TODO: why are they repeated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_corpus.df(\"VACUUM ANALYZE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Rewrite documentation and merge onto main. This is basically ready.\n",
    "# TODO: simplify process_text flowline. default for helper?? process > create > return? > clean?\n",
    "# TODO: Brown as default corpus.\n",
    "# > this for after cogsci\n",
    "# TODO: 4-grams. Should need minimal modification. Challenge might be RAM. Consider implementing an option to work from disk with duckdb?\n",
    "# > This for after cogsci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = pd.read_csv('2GPTEmpathicDialoguesDataset (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_utterances = gpt_data.processed.apply(mwu_measures.process_text)\n",
    "gpt_prompts = gpt_data.prompt.apply(mwu_measures.process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_text = pd.concat([gpt_utterances, gpt_prompts])\n",
    "gpt_text = gpt_text.explode()\n",
    "gpt_text = gpt_text.dropna()\n",
    "gpt_text = gpt_text.drop_duplicates().dropna().reset_index(drop=True)\n",
    "text_batches = [gpt_text.iloc[i*50000:(i+1)*50000].copy() for i in range(int(len(gpt_text) / 50000) + 1)]\n",
    "text_batches = [batch.to_list() for batch in text_batches]\n",
    "nice_weights = {'token_freq': 1/8, 'dispersion': 1/4, 'type_1': 1/16, 'type_2': 1/8, 'entropy_1': 1/16, 'entropy_2': 1/8, 'fw_assoc': 1/8, 'bw_assoc': 1/16}\n",
    "gpt_text_mwu = []\n",
    "i = 0\n",
    "for batch in text_batches:\n",
    "    print(round(i / len(text_batches), 2))\n",
    "    gpt_text_mwu.append(helper.get_score_batch(batch, weights=nice_weights, from_text=True))\n",
    "    i += 1\n",
    "\n",
    "pd.concat((result[0] for result in gpt_text_mwu)).sort_values(by = 'ngram').to_csv('gpt_mwu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data_1 = pd.read_csv('test.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data_2 = pd.read_csv('train.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data_3 = pd.read_csv('valid.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data = pd.concat([human_data_1, human_data_2, human_data_3]).reset_index(drop=True)\n",
    "human_data['utterance'] = human_data['utterance'].str.replace('_comma_', ' , ')\n",
    "human_data['prompt'] = human_data['prompt'].str.replace('_comma_', ' , ')\n",
    "human_data['utterance'] = human_data['utterance'].str.replace('n t ', \"n't \", regex=False)\n",
    "human_data['prompt'] = human_data['prompt'].str.replace('n t ', \"n't \", regex=False)\n",
    "human_data['utterance'] = human_data['utterance'].str.replace(r'n t[$\\.]', \"n't\", regex=True)\n",
    "human_data['prompt'] = human_data['prompt'].str.replace(r'n t[$\\.]', \"n't\", regex=True)\n",
    "# human_data['prompt'] = human_data['prompt'].str.replace('wasnt', \"wasn't\", regex=True)\n",
    "# human_data['utterance'] = human_data['utterance'].str.replace('wasnt', \"wasn't\", regex=True)\n",
    "\n",
    "human_data['utterance'] = human_data.utterance.apply(mwu_measures.process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = pd.read_csv('human_mwu_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = dict(zip(human_scores['ngram'].to_list(), human_scores['mwu_score'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data = human_data.explode('utterance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data = human_data[~human_data['utterance'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data['mwu_score'] = human_data.utterance.apply(lambda x: human_scores[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data = human_data.reset_index(drop=True)\n",
    "human_data['trigram_id'] = human_data.index // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data[['conv_id', 'utterance_idx', 'prompt', 'speaker_idx', 'utterance', 'mwu_score', 'trigram_id']].to_csv('human_trigram_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      0,       0,       1,       1,       2,       2,       3,       3,\n",
       "             4,       4,\n",
       "       ...\n",
       "       1626548, 1626549, 1626549, 1626550, 1626550, 1626551, 1626551, 1626552,\n",
       "       1626552, 1626553],\n",
       "      dtype='int64', length=3253107)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = pd.read_csv('2GPTEmpathicDialoguesDataset (1).csv')\n",
    "gpt_data['utterance'] = gpt_data.processed.apply(mwu_measures.process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_scores = pd.read_csv('gpt_mwu_scores.csv')\n",
    "gpt_scores = dict(zip(gpt_scores['ngram'].to_list(), gpt_scores['mwu_score'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = gpt_data.explode('utterance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = gpt_data[~gpt_data['utterance'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data['mwu_score'] = gpt_data.utterance.apply(lambda x: gpt_scores[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = gpt_data.reset_index(drop=True)\n",
    "gpt_data['trigram_id'] = gpt_data.index // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conv_id</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>gptgen</th>\n",
       "      <th>processed</th>\n",
       "      <th>utterance</th>\n",
       "      <th>mwu_score</th>\n",
       "      <th>trigram_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>assistant1: I know exactly what you mean. Ther...</td>\n",
       "      <td>i know exactly what you mean. there's somethi...</td>\n",
       "      <td>i know</td>\n",
       "      <td>0.492501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>assistant1: I know exactly what you mean. Ther...</td>\n",
       "      <td>i know exactly what you mean. there's somethi...</td>\n",
       "      <td>i know exactly</td>\n",
       "      <td>0.416521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>assistant1: I know exactly what you mean. Ther...</td>\n",
       "      <td>i know exactly what you mean. there's somethi...</td>\n",
       "      <td>know exactly</td>\n",
       "      <td>0.511043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>assistant1: I know exactly what you mean. Ther...</td>\n",
       "      <td>i know exactly what you mean. there's somethi...</td>\n",
       "      <td>know exactly what</td>\n",
       "      <td>0.574656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>assistant1: I know exactly what you mean. Ther...</td>\n",
       "      <td>i know exactly what you mean. there's somethi...</td>\n",
       "      <td>exactly what</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805080</th>\n",
       "      <td>19532</td>\n",
       "      <td>hit:9_conv:19</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>one time when I was in preschool_comma_ I had ...</td>\n",
       "      <td>assistant1: Listener: Oh no, that sounds reall...</td>\n",
       "      <td>oh no, that sounds really embarrassing! how ...</td>\n",
       "      <td>more comfortable</td>\n",
       "      <td>0.571433</td>\n",
       "      <td>5902540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805081</th>\n",
       "      <td>19532</td>\n",
       "      <td>hit:9_conv:19</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>one time when I was in preschool_comma_ I had ...</td>\n",
       "      <td>assistant1: Listener: Oh no, that sounds reall...</td>\n",
       "      <td>oh no, that sounds really embarrassing! how ...</td>\n",
       "      <td>more comfortable and</td>\n",
       "      <td>0.479777</td>\n",
       "      <td>5902540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805082</th>\n",
       "      <td>19532</td>\n",
       "      <td>hit:9_conv:19</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>one time when I was in preschool_comma_ I had ...</td>\n",
       "      <td>assistant1: Listener: Oh no, that sounds reall...</td>\n",
       "      <td>oh no, that sounds really embarrassing! how ...</td>\n",
       "      <td>comfortable and</td>\n",
       "      <td>0.506829</td>\n",
       "      <td>5902541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805083</th>\n",
       "      <td>19532</td>\n",
       "      <td>hit:9_conv:19</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>one time when I was in preschool_comma_ I had ...</td>\n",
       "      <td>assistant1: Listener: Oh no, that sounds reall...</td>\n",
       "      <td>oh no, that sounds really embarrassing! how ...</td>\n",
       "      <td>comfortable and confident</td>\n",
       "      <td>0.459067</td>\n",
       "      <td>5902541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805084</th>\n",
       "      <td>19532</td>\n",
       "      <td>hit:9_conv:19</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>one time when I was in preschool_comma_ I had ...</td>\n",
       "      <td>assistant1: Listener: Oh no, that sounds reall...</td>\n",
       "      <td>oh no, that sounds really embarrassing! how ...</td>\n",
       "      <td>and confident</td>\n",
       "      <td>0.522667</td>\n",
       "      <td>5902542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11805085 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0        conv_id      context  \\\n",
       "0                  0   hit:0_conv:1  sentimental   \n",
       "1                  0   hit:0_conv:1  sentimental   \n",
       "2                  0   hit:0_conv:1  sentimental   \n",
       "3                  0   hit:0_conv:1  sentimental   \n",
       "4                  0   hit:0_conv:1  sentimental   \n",
       "...              ...            ...          ...   \n",
       "11805080       19532  hit:9_conv:19  embarrassed   \n",
       "11805081       19532  hit:9_conv:19  embarrassed   \n",
       "11805082       19532  hit:9_conv:19  embarrassed   \n",
       "11805083       19532  hit:9_conv:19  embarrassed   \n",
       "11805084       19532  hit:9_conv:19  embarrassed   \n",
       "\n",
       "                                                     prompt  \\\n",
       "0         I remember going to the fireworks with my best...   \n",
       "1         I remember going to the fireworks with my best...   \n",
       "2         I remember going to the fireworks with my best...   \n",
       "3         I remember going to the fireworks with my best...   \n",
       "4         I remember going to the fireworks with my best...   \n",
       "...                                                     ...   \n",
       "11805080  one time when I was in preschool_comma_ I had ...   \n",
       "11805081  one time when I was in preschool_comma_ I had ...   \n",
       "11805082  one time when I was in preschool_comma_ I had ...   \n",
       "11805083  one time when I was in preschool_comma_ I had ...   \n",
       "11805084  one time when I was in preschool_comma_ I had ...   \n",
       "\n",
       "                                                     gptgen  \\\n",
       "0         assistant1: I know exactly what you mean. Ther...   \n",
       "1         assistant1: I know exactly what you mean. Ther...   \n",
       "2         assistant1: I know exactly what you mean. Ther...   \n",
       "3         assistant1: I know exactly what you mean. Ther...   \n",
       "4         assistant1: I know exactly what you mean. Ther...   \n",
       "...                                                     ...   \n",
       "11805080  assistant1: Listener: Oh no, that sounds reall...   \n",
       "11805081  assistant1: Listener: Oh no, that sounds reall...   \n",
       "11805082  assistant1: Listener: Oh no, that sounds reall...   \n",
       "11805083  assistant1: Listener: Oh no, that sounds reall...   \n",
       "11805084  assistant1: Listener: Oh no, that sounds reall...   \n",
       "\n",
       "                                                  processed  \\\n",
       "0          i know exactly what you mean. there's somethi...   \n",
       "1          i know exactly what you mean. there's somethi...   \n",
       "2          i know exactly what you mean. there's somethi...   \n",
       "3          i know exactly what you mean. there's somethi...   \n",
       "4          i know exactly what you mean. there's somethi...   \n",
       "...                                                     ...   \n",
       "11805080    oh no, that sounds really embarrassing! how ...   \n",
       "11805081    oh no, that sounds really embarrassing! how ...   \n",
       "11805082    oh no, that sounds really embarrassing! how ...   \n",
       "11805083    oh no, that sounds really embarrassing! how ...   \n",
       "11805084    oh no, that sounds really embarrassing! how ...   \n",
       "\n",
       "                          utterance  mwu_score  trigram_id  \n",
       "0                            i know   0.492501           0  \n",
       "1                    i know exactly   0.416521           0  \n",
       "2                      know exactly   0.511043           1  \n",
       "3                 know exactly what   0.574656           1  \n",
       "4                      exactly what   0.597637           2  \n",
       "...                             ...        ...         ...  \n",
       "11805080           more comfortable   0.571433     5902540  \n",
       "11805081       more comfortable and   0.479777     5902540  \n",
       "11805082            comfortable and   0.506829     5902541  \n",
       "11805083  comfortable and confident   0.459067     5902541  \n",
       "11805084              and confident   0.522667     5902542  \n",
       "\n",
       "[11805085 rows x 9 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data[['conv_id', 'prompt', 'utterance', 'mwu_score', 'trigram_id']].to_csv('gpt_trigram_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwu_measures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
