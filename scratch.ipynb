{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import re\n",
    "# from collections import defaultdict, Counter\n",
    "# # from itertools import groupby\n",
    "# # from nltk import flatten\n",
    "# # from nltk.util import trigrams as get_trigrams\n",
    "# from mwu_measures.preprocessing_corpus import clean_bnc_line, preprocess_bnc\n",
    "# # import mwu_measures\n",
    "# from mwu_measures.processing_corpus import Corpus\n",
    "import mwu_measures\n",
    "from mwu_measures.compute_functions import min_max_norm\n",
    "from mwu_measures import compute_functions\n",
    "from mwu_measures import processing_corpus\n",
    "# from mwu_measures.mwu_functions import get_association, get_entropy_dif\n",
    "from collections import defaultdict, Counter\n",
    "# from nltk import FreqDist\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88073 lines processed\n",
      "178347 lines processed\n",
      "251137 lines processed\n",
      "331017 lines processed\n",
      "417430 lines processed\n",
      "515742 lines processed\n",
      "613852 lines processed\n",
      "688626 lines processed\n",
      "771777 lines processed\n",
      "859529 lines processed\n",
      "942900 lines processed\n",
      "1047131 lines processed\n",
      "1123302 lines processed\n",
      "1235027 lines processed\n",
      "1333326 lines processed\n",
      "1429373 lines processed\n",
      "1524762 lines processed\n",
      "1622597 lines processed\n",
      "1725782 lines processed\n",
      "1809093 lines processed\n",
      "1884758 lines processed\n",
      "1961270 lines processed\n",
      "2040098 lines processed\n",
      "2120332 lines processed\n",
      "2197854 lines processed\n",
      "2289980 lines processed\n",
      "2373487 lines processed\n",
      "2463569 lines processed\n",
      "2537313 lines processed\n",
      "2608775 lines processed\n",
      "2690149 lines processed\n",
      "2759435 lines processed\n",
      "2861830 lines processed\n",
      "2953964 lines processed\n",
      "3046485 lines processed\n",
      "3145655 lines processed\n",
      "3259778 lines processed\n",
      "3376309 lines processed\n",
      "3475369 lines processed\n",
      "3566620 lines processed\n",
      "3654773 lines processed\n",
      "3770351 lines processed\n",
      "3855412 lines processed\n",
      "3938084 lines processed\n",
      "4033231 lines processed\n",
      "4130649 lines processed\n",
      "4237372 lines processed\n",
      "4416828 lines processed\n",
      "4622940 lines processed\n",
      "4747128 lines processed\n",
      "4823611 lines processed\n",
      "5011537 lines processed\n",
      "5156032 lines processed\n",
      "5241328 lines processed\n",
      "5333426 lines processed\n",
      "5416742 lines processed\n",
      "5505469 lines processed\n",
      "5581625 lines processed\n",
      "5668824 lines processed\n",
      "5759333 lines processed\n",
      "5838998 lines processed\n",
      "5921184 lines processed\n",
      "6006547 lines processed\n",
      "6026276 lines processed\n"
     ]
    }
   ],
   "source": [
    "this_corpus = processing_corpus.process_corpus(corpus_name = 'bnc', corpus_dir='bnc_tokenized.txt', chunk_size=10000000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_examples = pd.read_csv('MultiwordExpression_Concreteness_Ratings.csv')\n",
    "mwu_examples['length'] = mwu_examples['Expression'].apply(lambda x: len(x.split()))\n",
    "mwu_examples = mwu_examples.loc[(mwu_examples['length'] == 2) | (mwu_examples['length'] == 3)]\n",
    "mwu_examples['Expression'] = mwu_examples['Expression'].apply(lambda x: x.lower())\n",
    "mwu_examples = mwu_examples.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_list = mwu_examples.Expression\n",
    "bigrams = [ngram.split() for ngram in ngram_list if len(ngram.split()) == 2]\n",
    "trigrams = [ngram.split() for ngram in ngram_list if len(ngram.split()) == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x18aeb50ae70>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_query = pd.DataFrame(trigrams, columns=['ug_1', 'ug_2', 'ug_3'])\n",
    "this_corpus.corpus_conn.execute(\"CREATE TEMPORARY TABLE trigram_query (ug_1 TEXT, ug_2 TEXT, ug_3 TEXT)\")\n",
    "this_corpus.corpus_conn.register('trigram_query_list', trigram_query)\n",
    "this_corpus.corpus_conn.execute(\"INSERT INTO trigram_query SELECT * FROM trigram_query_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_per_corpus = this_corpus.corpus_conn.execute(\"\"\"\n",
    "    SELECT * FROM trigram_db \n",
    "    WHERE (ug_1 IN (SELECT ug_1 FROM trigram_query) AND ug_2 IN (SELECT ug_2 FROM trigram_query)) OR (ug_3 IN (SELECT ug_3 FROM trigram_query))\n",
    "\"\"\").fetch_df()\n",
    "# trigram_total = this_corpus.corpus_conn.execute(\"\"\"\n",
    "#     SELECT ug_1, ug_2, ug_3, sum(freq) as freq FROM trigram_db \n",
    "#     WHERE (ug_1 IN (SELECT ug_1 FROM trigram_query) AND ug_2 IN (SELECT ug_2 FROM trigram_query)) OR (ug_3 IN (SELECT ug_3 FROM trigram_query))\n",
    "#     GROUP BY (ug_1, ug_2, ug_3)\n",
    "# \"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x18aeb50ae70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_query = pd.DataFrame(bigrams, columns=['ug_1', 'ug_2'])\n",
    "this_corpus.corpus_conn.execute(\"CREATE TEMPORARY TABLE bigram_query (ug_1 TEXT, ug_2 TEXT)\")\n",
    "this_corpus.corpus_conn.register('bigram_query_list', bigram_query)\n",
    "this_corpus.corpus_conn.execute(\"INSERT INTO bigram_query SELECT * FROM bigram_query_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x189d27cd0b0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this_corpus.corpus_conn.execute(\"DROP TABLE bigram_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_per_corpus = this_corpus.corpus_conn.execute(\"\"\"\n",
    "    SELECT corpus, ug_1, ug_2, sum(freq) AS freq FROM trigram_db \n",
    "    WHERE (ug_1 IN (SELECT ug_1 FROM bigram_query)) OR (ug_2 IN (SELECT ug_2 FROM bigram_query))\n",
    "    GROUP BY corpus, ug_1, ug_2\n",
    "\"\"\").fetch_df()\n",
    "# bigram_total = this_corpus.corpus_conn.execute(\"\"\"\n",
    "#     SELECT ug_1, ug_2, sum(freq) AS freq FROM trigram_db \n",
    "#     WHERE (ug_1 IN (SELECT ug_1 FROM bigram_query)) OR (ug_2 IN (SELECT ug_2 FROM bigram_query))\n",
    "#     GROUP BY ug_1, ug_2\n",
    "# \"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fw_dists \u001b[38;5;241m=\u001b[39m {ngram_1: {corpus:  Counter(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mug_2\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq\u001b[39m\u001b[38;5;124m'\u001b[39m]))) \u001b[38;5;28;01mfor\u001b[39;00m corpus, data \u001b[38;5;129;01min\u001b[39;00m group\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus\u001b[39m\u001b[38;5;124m'\u001b[39m)} \u001b[38;5;28;01mfor\u001b[39;00m ngram_1, group \u001b[38;5;129;01min\u001b[39;00m bigram_per_corpus\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mug_1\u001b[39m\u001b[38;5;124m'\u001b[39m)}\n",
      "File \u001b[1;32mc:\\Users\\contr\\anaconda3\\envs\\mwu_measures\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:618\u001b[0m, in \u001b[0;36mBaseGrouper.get_iterator\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_iterator\u001b[39m(\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28mself\u001b[39m, data: NDFrameT, axis: AxisInt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    609\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mtuple\u001b[39m[Hashable, NDFrameT]]:\n\u001b[0;32m    610\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;124;03m    Groupby iterator\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;124;03m    for each group\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m     splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_splitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_keys_seq\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, splitter)\n",
      "File \u001b[1;32mc:\\Users\\contr\\anaconda3\\envs\\mwu_measures\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:634\u001b[0m, in \u001b[0;36mBaseGrouper._get_splitter\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;124;03m-------\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03mGenerator yielding subsetted objects\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    629\u001b[0m ids, _, ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_splitter(\n\u001b[0;32m    631\u001b[0m     data,\n\u001b[0;32m    632\u001b[0m     ids,\n\u001b[0;32m    633\u001b[0m     ngroups,\n\u001b[1;32m--> 634\u001b[0m     sorted_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sorted_ids\u001b[49m,\n\u001b[0;32m    635\u001b[0m     sort_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_idx,\n\u001b[0;32m    636\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    637\u001b[0m )\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\contr\\anaconda3\\envs\\mwu_measures\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:950\u001b[0m, in \u001b[0;36mBaseGrouper._sorted_ids\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sorted_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]:\n\u001b[0;32m    949\u001b[0m     ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[1;32m--> 950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# takes too long, filter DF first\n",
    "\n",
    "fw_dists = {ngram_1: {corpus:  Counter(dict(zip(data['ug_2'], data['freq']))) for corpus, data in group.groupby('corpus')} for ngram_1, group in bigram_per_corpus.groupby('ug_1')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>ug_1</th>\n",
       "      <th>ug_2</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11858</th>\n",
       "      <td>A</td>\n",
       "      <td>been</td>\n",
       "      <td>reinstated</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11859</th>\n",
       "      <td>A</td>\n",
       "      <td>and</td>\n",
       "      <td>jonathan</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11860</th>\n",
       "      <td>A</td>\n",
       "      <td>to</td>\n",
       "      <td>both</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11861</th>\n",
       "      <td>A</td>\n",
       "      <td>light</td>\n",
       "      <td>and</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11862</th>\n",
       "      <td>A</td>\n",
       "      <td>with</td>\n",
       "      <td>isla</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975674</th>\n",
       "      <td>A</td>\n",
       "      <td>sandown</td>\n",
       "      <td>in</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975675</th>\n",
       "      <td>A</td>\n",
       "      <td>rather</td>\n",
       "      <td>minor</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975676</th>\n",
       "      <td>A</td>\n",
       "      <td>lowndes</td>\n",
       "      <td>will</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975677</th>\n",
       "      <td>A</td>\n",
       "      <td>index</td>\n",
       "      <td>climbing</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975678</th>\n",
       "      <td>A</td>\n",
       "      <td>england's</td>\n",
       "      <td>match</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609174 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus       ug_1        ug_2   freq\n",
       "11858         A       been  reinstated    2.0\n",
       "11859         A        and    jonathan   23.0\n",
       "11860         A         to        both  213.0\n",
       "11861         A      light         and  263.0\n",
       "11862         A       with        isla    1.0\n",
       "...         ...        ...         ...    ...\n",
       "10975674      A    sandown          in    1.0\n",
       "10975675      A     rather       minor    1.0\n",
       "10975676      A    lowndes        will    1.0\n",
       "10975677      A      index    climbing    1.0\n",
       "10975678      A  england's       match    1.0\n",
       "\n",
       "[1609174 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw_dists['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>ug_1</th>\n",
       "      <th>ug_2</th>\n",
       "      <th>ug_3</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>START</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>o</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>C</td>\n",
       "      <td>j</td>\n",
       "      <td>k</td>\n",
       "      <td>r</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>C</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>j</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>C</td>\n",
       "      <td>h</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>C</td>\n",
       "      <td>h</td>\n",
       "      <td>k</td>\n",
       "      <td>o</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>r</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    corpus   ug_1 ug_2 ug_3  freq\n",
       "0        A  START    a    d   1.0\n",
       "1        A      b    f    g   1.0\n",
       "2        A      o    a    c   1.0\n",
       "3        A      a    d    c   1.0\n",
       "4        A      d    c    b   1.0\n",
       "..     ...    ...  ...  ...   ...\n",
       "96       C      j    k    r   1.0\n",
       "97       C      r    e    j   1.0\n",
       "98       C      h    f    d   1.0\n",
       "99       C      h    k    o   1.0\n",
       "100      C      c    b    r   1.0\n",
       "\n",
       "[101 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_corpus.corpus_conn.execute(\"SELECT * FROM trigram_db ORDER BY corpus\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8928 lines processed\n",
      "16500 lines processed\n",
      "25755 lines processed\n",
      "34338 lines processed\n",
      "42803 lines processed\n",
      "52217 lines processed\n",
      "61689 lines processed\n",
      "71326 lines processed\n",
      "80991 lines processed\n",
      "90366 lines processed\n",
      "98040 lines processed\n",
      "105999 lines processed\n",
      "114462 lines processed\n",
      "123188 lines processed\n",
      "130358 lines processed\n",
      "137924 lines processed\n",
      "147611 lines processed\n",
      "157164 lines processed\n",
      "168734 lines processed\n",
      "178303 lines processed\n",
      "188473 lines processed\n",
      "196901 lines processed\n",
      "206573 lines processed\n",
      "220860 lines processed\n",
      "237194 lines processed\n",
      "250060 lines processed\n",
      "261943 lines processed\n",
      "270684 lines processed\n",
      "278913 lines processed\n",
      "287810 lines processed\n",
      "296127 lines processed\n",
      "301046 lines processed\n",
      "First time normalizing. Need to consolidate...\n"
     ]
    }
   ],
   "source": [
    "this_corpus = mwu_measures.processing_corpus.process_corpus(corpus_name='bnc', corpus_dir='small_corpus.txt', verbose=True, chunk_size=1000000)\n",
    "this_corpus.create_totals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwu_measures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
