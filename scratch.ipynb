{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwu_measures\n",
    "import pandas as pd\n",
    "import mwu_measures.preprocessing_corpus\n",
    "import mwu_measures.processing_corpus\n",
    "from mwu_measures.corpus_helper import Fetcher\n",
    "from mwu_measures.corpus import Corpus\n",
    "import duckdb\n",
    "from rich.progress import Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mwu_examples = pd.read_csv('MultiwordExpression_Concreteness_Ratings.csv')\n",
    "mwu_examples['length'] = mwu_examples['Expression'].apply(lambda x: len(x.split()))\n",
    "mwu_examples = mwu_examples.loc[(mwu_examples['length'] == 2) | (mwu_examples['length'] == 3)]\n",
    "mwu_examples['Expression'] = mwu_examples['Expression'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mwu_measures.processing_corpus.make_processed_corpus('coca', 'mwu_measures/corpora/coca_texts/', chunk_size=10, verbose=True)\n",
    "# wrapper = lp(mwu_measures.processing_corpus.get_processed_corpus)\n",
    "# this_corpus = mwu_measures.processing_corpus.get_processed_corpus('bnc', 'small_corpus.txt', chunk_size=10000000, verbose=False)\n",
    "# this_corpus = mwu_measures.processing_corpus.make_processed_corpus(test_corpus=True, threshold=0)\n",
    "# lp.print_stats()\n",
    "# ngram_selection = [ngram.split() for ngram in ngram_selection]\n",
    "# ngram_chunks = np.array_split(ngram_selection, 100)\n",
    "bigrams = ['b d', 'c b', 'a c']\n",
    "# bigrams = [['b', 'd'], ['c', 'b'], ['a', 'c']]\n",
    "\n",
    "# helper = Fetcher(this_corpus)\n",
    "# 340 seconds for all _acad_. Not bad, not the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preexisting corpus\n"
     ]
    }
   ],
   "source": [
    "test_corpus = Corpus(\"test\")\n",
    "helper = Fetcher(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e25fd25d2754622a11a76723ae07151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f02fbf566b489f9909aecca63980d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_1</th>\n",
       "      <th>comp_2</th>\n",
       "      <th>token_freq</th>\n",
       "      <th>dispersion</th>\n",
       "      <th>typef_1</th>\n",
       "      <th>typef_2</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_2</th>\n",
       "      <th>fw_assoc</th>\n",
       "      <th>bw_assoc</th>\n",
       "      <th>ngram_length</th>\n",
       "      <th>ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.199452</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.069372</td>\n",
       "      <td>0.029215</td>\n",
       "      <td>0.175159</td>\n",
       "      <td>0.268079</td>\n",
       "      <td>2</td>\n",
       "      <td>b d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.811623</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.095055</td>\n",
       "      <td>0.225603</td>\n",
       "      <td>0.620430</td>\n",
       "      <td>0.404903</td>\n",
       "      <td>2</td>\n",
       "      <td>c b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.564654</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.039036</td>\n",
       "      <td>0.430938</td>\n",
       "      <td>0.279442</td>\n",
       "      <td>2</td>\n",
       "      <td>a c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comp_1 comp_2  token_freq  dispersion  typef_1  typef_2  entropy_1  \\\n",
       "0      b      d         3.0    0.199452        6        9   0.069372   \n",
       "1      c      b         5.0    0.811623        8        4   0.095055   \n",
       "2      a      c         2.0    0.564654        6        4   0.002592   \n",
       "\n",
       "   entropy_2  fw_assoc  bw_assoc  ngram_length ngram  \n",
       "0   0.029215  0.175159  0.268079             2   b d  \n",
       "1   0.225603  0.620430  0.404903             2   c b  \n",
       "2   0.039036  0.430938  0.279442             2   a c  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = helper.get_score_batch(bigrams, normalized=False)\n",
    "x['dispersion'] = 1 - x['dispersion']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preexisting corpus\n"
     ]
    }
   ],
   "source": [
    "this_corpus = Corpus(\"coca\")\n",
    "helper = Fetcher(this_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_corpus(\"CREATE OR REPLACE TABLE trigram_db AS SELECT * FROM trigram_db ORDER BY ug_1, ug_2, ug_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = mwu_examples['Expression'].tolist()\n",
    "# ngrams = [[ngram[0] + ' ' + ngram[1], ngram[2]] if len(ngram) == 3 else ngram for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52aee0eb3ff944dbbbd77c781a437934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63a2d5babfe4caaad9ca649f97bebfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b7a8d7f04e4b3f892dbae87d646a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170eb58294a54f1987593d43cb4a1292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2189089d66174da18488ebfc9c9867de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9134bbe8bc24c2f91d477bc7d0e7137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c116fb86b943f1867c6302b7c16153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4ed218e2e045ed8a7dd36cfae35d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = helper.get_score_batch(ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].sort_values('mwu_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x[0][~x[0]['ngram_length'].isna()].drop_duplicates().sort_values(by=['mwu_score'], ascending=False).iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data_1 = pd.read_csv('test.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data_2 = pd.read_csv('train.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data_3 = pd.read_csv('valid.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data = pd.concat([human_data_1, human_data_2, human_data_3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data['utterance'] = human_data['utterance'].str.replace('_comma_', ' , ')\n",
    "human_data['prompt'] = human_data['prompt'].str.replace('_comma_', ' , ')\n",
    "human_data['utterance'] = human_data['utterance'].str.replace('n t ', \"n't \", regex=False)\n",
    "human_data['prompt'] = human_data['prompt'].str.replace('n t ', \"n't \", regex=False)\n",
    "human_data['utterance'] = human_data['utterance'].str.replace(r'n t[$\\.]', \"n't\", regex=True)\n",
    "human_data['prompt'] = human_data['prompt'].str.replace(r'n t[$\\.]', \"n't\", regex=True)\n",
    "# human_data['prompt'] = human_data['prompt'].str.replace('wasnt', \"wasn't\", regex=True)\n",
    "# human_data['utterance'] = human_data['utterance'].str.replace('wasnt', \"wasn't\", regex=True)\n",
    "\n",
    "human_utterances = human_data.utterance.apply(mwu_measures.process_text)\n",
    "human_prompts = human_data.prompt.apply(mwu_measures.process_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text = pd.concat([human_utterances, human_prompts])\n",
    "human_text = human_text.explode()\n",
    "human_text = human_text.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text = human_text.drop_duplicates().dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batches = [human_text.iloc[i*50000:(i+1)*50000].copy() for i in range(int(len(human_text) / 50000) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batches = [batch.to_list() for batch in text_batches]\n",
    "# TODO: does wasn t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = {'token_freq': 1/8, 'dispersion': 1/4, 'type_1': 1/16, 'type_2': 1/8, 'entropy_1': 1/16, 'entropy_2': 1/8, 'fw_assoc': 1/8, 'bw_assoc': 1/16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text_mwu = []\n",
    "i = 0\n",
    "for batch in text_batches:\n",
    "    print((i / len(text_batches)))\n",
    "    human_text_mwu.append(helper.get_score_batch(batch, weights=test_weights, from_text=True))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text_mwu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((result[0] for result in human_text_mwu)).sort_values(by = 'ngram').to_csv('human_mwu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text_mwu.drop_duplicates().sort_values(by=['mwu_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LO HICE!!!\n",
    "this_corpus.create_query(ngrams, 'big_1', 'ug_3')\n",
    "this_corpus.get_ngram_scores('big_1', 'ug_3', 3, [-0.1, 0.1])['normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_corpus.df(\"SELECT * FROM trigram_db WHERE big_1 = HASH('read up') AND ug_3 = HASH('about')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper(\"SELECT DISTINCT * FROM entropy_diffs\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy broken for trigrams again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = helper.get_score_batch(mwu_examples['Expression']).sort_values(by='mwu_score')\n",
    "x[x['ngram_length'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper(\"SELECT * FROM raw_measures\", df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = ['come in handy', 'family friend', 'database management system', 'one hundred percent', 'line of control', 'like a', 'boiled potatoes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = helper\n",
    "normalized=True\n",
    "# self.get_score_batch(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Hello! Come in and eat boiled potatoes they are one hundred percent good.\\nI remember when we met in the year 2000'\n",
    "sentence = mwu_measures.process_text(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.create_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_score_batch(sentence)\n",
    "# TODO: why are they repeated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_corpus.df(\"VACUUM ANALYZE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Rewrite documentation and merge onto main. This is basically ready.\n",
    "# TODO: simplify process_text flowline. default for helper?? process > create > return? > clean?\n",
    "# TODO: Brown as default corpus.\n",
    "# > this for after cogsci\n",
    "# TODO: 4-grams. Should need minimal modification. Challenge might be RAM. Consider implementing an option to work from disk with duckdb?\n",
    "# > This for after cogsci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = pd.read_csv('2GPTEmpathicDialoguesDataset (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_utterances = gpt_data.processed.apply(mwu_measures.process_text)\n",
    "gpt_prompts = gpt_data.prompt.apply(mwu_measures.process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_text = pd.concat([gpt_utterances, gpt_prompts])\n",
    "gpt_text = gpt_text.explode()\n",
    "gpt_text = gpt_text.dropna()\n",
    "gpt_text = gpt_text.drop_duplicates().dropna().reset_index(drop=True)\n",
    "text_batches = [gpt_text.iloc[i*50000:(i+1)*50000].copy() for i in range(int(len(gpt_text) / 50000) + 1)]\n",
    "text_batches = [batch.to_list() for batch in text_batches]\n",
    "nice_weights = {'token_freq': 1/8, 'dispersion': 1/4, 'type_1': 1/16, 'type_2': 1/8, 'entropy_1': 1/16, 'entropy_2': 1/8, 'fw_assoc': 1/8, 'bw_assoc': 1/16}\n",
    "gpt_text_mwu = []\n",
    "i = 0\n",
    "for batch in text_batches:\n",
    "    print(round(i / len(text_batches), 2))\n",
    "    gpt_text_mwu.append(helper.get_score_batch(batch, weights=nice_weights, from_text=True))\n",
    "    i += 1\n",
    "\n",
    "pd.concat((result[0] for result in gpt_text_mwu)).sort_values(by = 'ngram').to_csv('gpt_mwu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data_1 = pd.read_csv('test.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data_2 = pd.read_csv('train.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data_3 = pd.read_csv('valid.csv', usecols=['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'])\n",
    "human_data = pd.concat([human_data_1, human_data_2, human_data_3]).reset_index(drop=True)\n",
    "human_data['utterance'] = human_data['utterance'].str.replace('_comma_', ' , ')\n",
    "human_data['prompt'] = human_data['prompt'].str.replace('_comma_', ' , ')\n",
    "human_data['utterance'] = human_data['utterance'].str.replace('n t ', \"n't \", regex=False)\n",
    "human_data['prompt'] = human_data['prompt'].str.replace('n t ', \"n't \", regex=False)\n",
    "human_data['utterance'] = human_data['utterance'].str.replace(r'n t[$\\.]', \"n't\", regex=True)\n",
    "human_data['prompt'] = human_data['prompt'].str.replace(r'n t[$\\.]', \"n't\", regex=True)\n",
    "# human_data['prompt'] = human_data['prompt'].str.replace('wasnt', \"wasn't\", regex=True)\n",
    "# human_data['utterance'] = human_data['utterance'].str.replace('wasnt', \"wasn't\", regex=True)\n",
    "\n",
    "human_data['utterance'] = human_data.utterance.apply(mwu_measures.process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = pd.read_csv('human_mwu_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = dict(zip(human_scores['ngram'].to_list(), human_scores['mwu_score'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data = human_data.explode('utterance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data = human_data[~human_data['utterance'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data['mwu_score'] = human_data.utterance.apply(lambda x: human_scores[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data = human_data.reset_index(drop=True)\n",
    "human_data['trigram_id'] = human_data.index // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data[['conv_id', 'utterance_idx', 'prompt', 'speaker_idx', 'utterance', 'mwu_score', 'trigram_id']].to_csv('human_trigram_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = pd.read_csv('2GPTEmpathicDialoguesDataset (1).csv')\n",
    "gpt_data['utterance'] = gpt_data.processed.apply(mwu_measures.process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_scores = pd.read_csv('gpt_mwu_scores.csv')\n",
    "gpt_scores = dict(zip(gpt_scores['ngram'].to_list(), gpt_scores['mwu_score'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = gpt_data.explode('utterance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = gpt_data[~gpt_data['utterance'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data['mwu_score'] = gpt_data.utterance.apply(lambda x: gpt_scores[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = gpt_data.reset_index(drop=True)\n",
    "gpt_data['trigram_id'] = gpt_data.index // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data[['conv_id', 'prompt', 'utterance', 'mwu_score', 'trigram_id']].to_csv('gpt_trigram_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwu_measures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
