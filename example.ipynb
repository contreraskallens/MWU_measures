{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwu_measures\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "mwu_measures = reload(mwu_measures)\n",
    "mwu_measures.mwu_functions = reload(mwu_measures.mwu_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to run the corpus processing function. Before trying other data, we can use the (hard-coded) synthetic corpus in Gries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_measures.process_corpus(test_corpus=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what a preprocess corpus should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A',\n",
       "        defaultdict(<function make_bigram_dict at 0x0000019FA49E49A0>, {'d': defaultdict(<class 'collections.Counter'>, {'a': Counter({'START': 1})}), 'c': defaultdict(<class 'collections.Counter'>, {'d': Counter({'a': 1}), 'h': Counter({'g': 1}), 'a': Counter({'o': 1}), 'c': Counter({'a': 1})}), 'b': defaultdict(<class 'collections.Counter'>, {'c': Counter({'d': 1, 'h': 1, 'c': 1}), 'e': Counter({'b': 1}), 'z': Counter({'y': 1})}), 'e': defaultdict(<class 'collections.Counter'>, {'b': Counter({'c': 1})}), 'f': defaultdict(<class 'collections.Counter'>, {'b': Counter({'e': 1})}), 'g': defaultdict(<class 'collections.Counter'>, {'f': Counter({'b': 1})}), 'h': defaultdict(<class 'collections.Counter'>, {'g': Counter({'f': 1})}), 'i': defaultdict(<class 'collections.Counter'>, {'b': Counter({'c': 1})}), 'j': defaultdict(<class 'collections.Counter'>, {'i': Counter({'b': 1})}), 'k': defaultdict(<class 'collections.Counter'>, {'j': Counter({'i': 1})}), 'a': defaultdict(<class 'collections.Counter'>, {'k': Counter({'j': 1}), 'o': Counter({'n': 1}), 'q': Counter({'r': 1}), 'n': Counter({'z': 1})}), 'y': defaultdict(<class 'collections.Counter'>, {'a': Counter({'k': 1})}), 'z': defaultdict(<class 'collections.Counter'>, {'y': Counter({'a': 1}), 'r': Counter({'x': 1})}), 'n': defaultdict(<class 'collections.Counter'>, {'b': Counter({'z': 1}), 'z': Counter({'r': 1})}), 'o': defaultdict(<class 'collections.Counter'>, {'n': Counter({'b': 1})}), 'p': defaultdict(<class 'collections.Counter'>, {'b': Counter({'c': 1})}), 'q': defaultdict(<class 'collections.Counter'>, {'p': Counter({'b': 1}), 'r': Counter({'q': 1})}), 'r': defaultdict(<class 'collections.Counter'>, {'q': Counter({'p': 1}), 'x': Counter({'a': 1})}), 'x': defaultdict(<class 'collections.Counter'>, {'a': Counter({'q': 1})}), 'END': defaultdict(<class 'collections.Counter'>, {'a': Counter({'n': 1})})})],\n",
       "       ['B',\n",
       "        defaultdict(<function make_bigram_dict at 0x0000019FA49E49A0>, {'i': defaultdict(<class 'collections.Counter'>, {'y': Counter({'START': 1})}), 'b': defaultdict(<class 'collections.Counter'>, {'i': Counter({'y': 1}), 'r': Counter({'q': 1}), 'c': Counter({'x': 1}), 'q': Counter({'p': 1}), 'z': Counter({'e': 1})}), 'c': defaultdict(<class 'collections.Counter'>, {'b': Counter({'i': 1}), 'x': Counter({'x': 1})}), 'p': defaultdict(<class 'collections.Counter'>, {'c': Counter({'b': 1}), 'o': Counter({'f': 1})}), 'x': defaultdict(<class 'collections.Counter'>, {'p': Counter({'c': 1}), 'b': Counter({'r': 1}), 'x': Counter({'b': 1})}), 'e': defaultdict(<class 'collections.Counter'>, {'x': Counter({'p': 1}), 'j': Counter({'d': 1})}), 'j': defaultdict(<class 'collections.Counter'>, {'e': Counter({'x': 1}), 'd': Counter({'b': 1})}), 'd': defaultdict(<class 'collections.Counter'>, {'j': Counter({'e': 1}), 'b': Counter({'c': 1, 'q': 1, 'z': 1})}), 'g': defaultdict(<class 'collections.Counter'>, {'d': Counter({'j': 1})}), 'n': defaultdict(<class 'collections.Counter'>, {'g': Counter({'d': 1})}), 'k': defaultdict(<class 'collections.Counter'>, {'n': Counter({'g': 1})}), 'q': defaultdict(<class 'collections.Counter'>, {'k': Counter({'n': 1}), 'p': Counter({'o': 1})}), 'r': defaultdict(<class 'collections.Counter'>, {'q': Counter({'k': 1})}), 'y': defaultdict(<class 'collections.Counter'>, {'d': Counter({'b': 1})}), 'z': defaultdict(<class 'collections.Counter'>, {'y': Counter({'d': 1}), 'e': Counter({'j': 1})}), 'f': defaultdict(<class 'collections.Counter'>, {'z': Counter({'y': 1})}), 'o': defaultdict(<class 'collections.Counter'>, {'f': Counter({'z': 1})}), 'END': defaultdict(<class 'collections.Counter'>, {'d': Counter({'b': 1})})})],\n",
       "       ['C',\n",
       "        defaultdict(<function make_bigram_dict at 0x0000019FA49E49A0>, {'g': defaultdict(<class 'collections.Counter'>, {'g': Counter({'START': 1}), 'd': Counter({'c': 1, 'r': 1}), 'j': Counter({'e': 1})}), 'i': defaultdict(<class 'collections.Counter'>, {'g': Counter({'g': 1})}), 'o': defaultdict(<class 'collections.Counter'>, {'i': Counter({'g': 1}), 'k': Counter({'h': 1})}), 'r': defaultdict(<class 'collections.Counter'>, {'o': Counter({'i': 1}), 'k': Counter({'j': 1}), 'b': Counter({'c': 1})}), 'j': defaultdict(<class 'collections.Counter'>, {'r': Counter({'o': 1}), 'j': Counter({'r': 1}), 'g': Counter({'d': 1}), 'e': Counter({'r': 1})}), 'b': defaultdict(<class 'collections.Counter'>, {'j': Counter({'j': 1}), 'c': Counter({'a': 1}), 'k': Counter({'g': 1})}), 'c': defaultdict(<class 'collections.Counter'>, {'b': Counter({'j': 1}), 'a': Counter({'o': 1})}), 'd': defaultdict(<class 'collections.Counter'>, {'c': Counter({'b': 1}), 'f': Counter({'h': 1}), 'r': Counter({'b': 1})}), 'k': defaultdict(<class 'collections.Counter'>, {'j': Counter({'g': 1}), 'h': Counter({'f': 1, 'd': 1}), 'g': Counter({'d': 1})}), 'e': defaultdict(<class 'collections.Counter'>, {'r': Counter({'k': 1})}), 'f': defaultdict(<class 'collections.Counter'>, {'g': Counter({'j': 1}), 'h': Counter({'k': 1})}), 'h': defaultdict(<class 'collections.Counter'>, {'f': Counter({'g': 1}), 'k': Counter({'h': 1}), 'd': Counter({'f': 1})}), 'a': defaultdict(<class 'collections.Counter'>, {'o': Counter({'k': 1})}), 'END': defaultdict(<class 'collections.Counter'>, {'b': Counter({'k': 1})})})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(mwu_measures.processing_corpus.TRIGRAM_BW.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then easily compare the results from Gries' paper. These are the bigrams in tables 3 and 4. Note that entropy_2 in table 4 uses a different calculation, and is not supposed to match with the paper.\n",
    "Also, because the author reports 1 - dispersion, I'll print it like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>token_freq</th>\n",
       "      <th>dispersion</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_2</th>\n",
       "      <th>assoc_f</th>\n",
       "      <th>assoc_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b d</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>3</td>\n",
       "      <td>0.199452</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.069372</td>\n",
       "      <td>0.029215</td>\n",
       "      <td>0.156592</td>\n",
       "      <td>0.261216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "      <td>0.811623</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.095055</td>\n",
       "      <td>0.225603</td>\n",
       "      <td>0.638064</td>\n",
       "      <td>0.421190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>0.564654</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.039036</td>\n",
       "      <td>0.332089</td>\n",
       "      <td>0.251953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ngram first second  token_freq  dispersion  type_1  type_2  entropy_1  \\\n",
       "0   b d     b      d           3    0.199452       6       9   0.069372   \n",
       "1   c b     c      b           5    0.811623       8       4   0.095055   \n",
       "2   a c     a      c           2    0.564654       6       4   0.002592   \n",
       "\n",
       "   entropy_2   assoc_f   assoc_b  \n",
       "0   0.029215  0.156592  0.261216  \n",
       "1   0.225603  0.638064  0.421190  \n",
       "2   0.039036  0.332089  0.251953  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = mwu_measures.get_mwu_scores(['b d', 'c b', 'a c']) # TODO: Token, type, and dispersion working. Entropy and association are bad.\n",
    "x['dispersion'] = 1 - x['dispersion']\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use real data and a real corpus. I used the BNC corpus because it's what I have at hand. This is currently the only corpus supported, but I'll add others soon. You have to get your own copy of the BNC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging....\n"
     ]
    }
   ],
   "source": [
    "mwu_measures.process_corpus('bnc', 'bnc_tokenized.txt', chunk_size=100000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7951633576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pympler import asizeof\n",
    "asizeof.asizeof(mwu_measures.processing_corpus.TRIGRAM_FW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the multiword units from Muraki et al., 2022 (provided in the directory), from here: https://osf.io/ksypa/. For now, we can only use the bigrams. All bigrams not occurring in the BNC will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_examples = pd.read_csv('MultiwordExpression_Concreteness_Ratings.csv')\n",
    "mwu_examples['length'] = mwu_examples['Expression'].apply(lambda x: len(x.split()))\n",
    "mwu_examples = mwu_examples.loc[(mwu_examples['length'] == 2) | (mwu_examples['length'] == 3)]\n",
    "mwu_examples['Expression'] = mwu_examples['Expression'].apply(lambda x: x.lower())\n",
    "print(f'Number of possible bigrams and trigrams: {len(mwu_examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_scores = mwu_measures.get_mwu_scores(mwu_examples.sample(1000)['Expression'], normalize=False, parallel=False, verbose=True)\n",
    "# Notice: very slow now for some ngrams. E.g., 'meted out'. Memory leak??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_scores = mwu_measures.get_mwu_scores(mwu_examples['Expression'][0:40], normalize=False, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_scores = mwu_measures.get_mwu_scores(mwu_examples['Expression'][0:100], normalize=True, entropy_limits=[-0.1, 0.1], scale_entropy=True, verbose=False, track_progress=True)\n",
    "# TODO: this could very easily be parallel https://dask.pydata.org/en/latest/\n",
    "# TODO: https://superfastpython.com/learning-paths/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my test computer, this took around 6 minutes, including the normalization step. In my laptop, it was more like 15. We can see how many we had to skip because they're not in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ngrams that occur in BNC: {len(mwu_scores['normalized'])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something very sloppy just as an illustration: relationship between concreteness and the MWU measures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_examples_filter = mwu_examples.loc[mwu_examples['Expression'].isin(list(mwu_scores['normalized']['ngram']))]\n",
    "concreteness_mwu = pd.merge(mwu_examples_filter, mwu_scores['normalized'], how='left', left_on='Expression', right_on='ngram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concreteness_mwu = concreteness_mwu.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y, X = dmatrices('Mean_C ~ token_freq + dispersion + type_1 + type_2 + entropy_1 + entropy_2 + assoc_f + assoc_b', data=concreteness_mwu, return_type='dataframe')\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We can also take an MWU score based on this. First we can take an average, and compare it with a weighted average. This will be part of the package shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_scores = concreteness_mwu[['token_freq', 'dispersion', 'type_1', 'type_2', 'entropy_1', 'entropy_2', 'assoc_f', 'assoc_b']]\n",
    "concreteness_mwu['mwu_score'] = only_scores.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concreteness_mwu['mwu_weighted_1'] = only_scores.apply(lambda x: np.average(x, weights=[0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]), axis=1)\n",
    "concreteness_mwu['mwu_weighted_2'] = only_scores.apply(lambda x: np.average(x, weights=[0.1, 0.3, 0.05, 0.05, 0.2, 0.2, 0.05, 0.05]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"mwu_score\", y=\"Mean_C\", data=concreteness_mwu, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"mwu_weighted_1\", y=\"Mean_C\", data=concreteness_mwu, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"mwu_weighted_2\", y=\"Mean_C\", data=concreteness_mwu, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the most interesting relationship, but it's a living. There you go!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwu_measures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
