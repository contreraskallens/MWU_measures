{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwu_measures\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "mwu_measures = reload(mwu_measures)\n",
    "mwu_measures.mwu_functions = reload(mwu_measures.mwu_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to run the corpus processing function. Before trying other data, we can use the (hard-coded) synthetic corpus in Gries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_measures.process_corpus(test_corpus=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what a preprocess corpus should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A',\n",
       "        Counter({'a': 5, 'b': 5, 'c': 4, 'z': 2, 'n': 2, 'q': 2, 'r': 2, 'd': 1, 'e': 1, 'f': 1, 'g': 1, 'h': 1, 'i': 1, 'j': 1, 'k': 1, 'y': 1, 'o': 1, 'p': 1, 'x': 1})],\n",
       "       ['B',\n",
       "        Counter({'b': 5, 'd': 4, 'x': 3, 'y': 2, 'c': 2, 'p': 2, 'e': 2, 'j': 2, 'q': 2, 'z': 2, 'i': 1, 'g': 1, 'n': 1, 'k': 1, 'r': 1, 'f': 1, 'o': 1})],\n",
       "       ['C',\n",
       "        Counter({'g': 5, 'j': 4, 'k': 4, 'r': 3, 'b': 3, 'd': 3, 'h': 3, 'o': 2, 'c': 2, 'f': 2, 'i': 1, 'e': 1, 'a': 1})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(mwu_measures.processing_corpus.UNIGRAM_FREQUENCIES_PC.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then easily compare the results from Gries' paper. These are the bigrams in tables 3 and 4. Note that entropy_2 in table 4 uses a different calculation, and is not supposed to match with the paper.\n",
    "Also, because the author reports 1 - dispersion, I'll print it like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>token_freq</th>\n",
       "      <th>dispersion</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_2</th>\n",
       "      <th>assoc_f</th>\n",
       "      <th>assoc_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b d</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>0.199126</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.083484</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0.043196</td>\n",
       "      <td>0.074341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "      <td>0.811873</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620430</td>\n",
       "      <td>0.404903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>0.565102</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316464</td>\n",
       "      <td>0.239136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ngram first second  token_freq  dispersion  type_1  type_2  entropy_1  \\\n",
       "0   b d     b      d           2    0.199126       5       9   0.083484   \n",
       "1   c b     c      b           5    0.811873       8       4   0.000000   \n",
       "2   a c     a      c           2    0.565102       6       4   0.000000   \n",
       "\n",
       "   entropy_2   assoc_f   assoc_b  \n",
       "0   0.015141  0.043196  0.074341  \n",
       "1   0.000000  0.620430  0.404903  \n",
       "2   0.000000  0.316464  0.239136  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = mwu_measures.get_mwu_scores(['b d', 'c b', 'a c']) # TODO: Discrepancias con TYPE1, ENTROPY, pero en b d. What?\n",
    "x['dispersion'] = 1 - x['dispersion']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores in use: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Using backend LokyBackend with 31 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Done   1 out of  31 | elapsed:    0.6s remaining:   18.4s\n",
      "[Parallel(n_jobs=31)]: Done   2 out of  31 | elapsed:    0.6s remaining:    9.2s\n",
      "[Parallel(n_jobs=31)]: Done   3 out of  31 | elapsed:    0.6s remaining:    6.0s\n",
      "[Parallel(n_jobs=31)]: Done   4 out of  31 | elapsed:    0.7s remaining:    4.9s\n",
      "[Parallel(n_jobs=31)]: Done   5 out of  31 | elapsed:    0.7s remaining:    3.9s\n",
      "[Parallel(n_jobs=31)]: Done   6 out of  31 | elapsed:    0.8s remaining:    3.2s\n",
      "[Parallel(n_jobs=31)]: Done   7 out of  31 | elapsed:    0.8s remaining:    2.7s\n",
      "[Parallel(n_jobs=31)]: Done   8 out of  31 | elapsed:    0.8s remaining:    2.3s\n",
      "[Parallel(n_jobs=31)]: Done   9 out of  31 | elapsed:    0.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=31)]: Done  10 out of  31 | elapsed:    0.8s remaining:    1.7s\n",
      "[Parallel(n_jobs=31)]: Done  11 out of  31 | elapsed:    0.8s remaining:    1.5s\n",
      "[Parallel(n_jobs=31)]: Done  12 out of  31 | elapsed:    0.8s remaining:    1.3s\n",
      "[Parallel(n_jobs=31)]: Done  13 out of  31 | elapsed:    0.8s remaining:    1.1s\n",
      "[Parallel(n_jobs=31)]: Done  14 out of  31 | elapsed:    0.8s remaining:    1.0s\n",
      "[Parallel(n_jobs=31)]: Done  15 out of  31 | elapsed:    0.8s remaining:    0.9s\n",
      "[Parallel(n_jobs=31)]: Done  16 out of  31 | elapsed:    0.8s remaining:    0.8s\n",
      "[Parallel(n_jobs=31)]: Done  17 out of  31 | elapsed:    0.8s remaining:    0.7s\n",
      "[Parallel(n_jobs=31)]: Done  18 out of  31 | elapsed:    0.9s remaining:    0.6s\n",
      "[Parallel(n_jobs=31)]: Done  19 out of  31 | elapsed:    0.9s remaining:    0.5s\n",
      "[Parallel(n_jobs=31)]: Done  20 out of  31 | elapsed:    0.9s remaining:    0.5s\n",
      "[Parallel(n_jobs=31)]: Done  21 out of  31 | elapsed:    0.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=31)]: Done  22 out of  31 | elapsed:    0.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=31)]: Done  23 out of  31 | elapsed:    0.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=31)]: Done  24 out of  31 | elapsed:    0.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=31)]: Done  25 out of  31 | elapsed:    0.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=31)]: Done  26 out of  31 | elapsed:    0.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=31)]: Done  27 out of  31 | elapsed:    0.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=31)]: Done  28 out of  31 | elapsed:    0.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=31)]: Done  29 out of  31 | elapsed:    0.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=31)]: Done  31 out of  31 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>token_freq</th>\n",
       "      <th>dispersion</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_2</th>\n",
       "      <th>assoc_f</th>\n",
       "      <th>assoc_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b d</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>0.199126</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.083484</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0.043196</td>\n",
       "      <td>0.074341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "      <td>0.811873</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620430</td>\n",
       "      <td>0.404903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>0.565102</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316464</td>\n",
       "      <td>0.239136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ngram first second  token_freq  dispersion  type_1  type_2  entropy_1  \\\n",
       "0   b d     b      d           2    0.199126       5       9   0.083484   \n",
       "1   c b     c      b           5    0.811873       8       4   0.000000   \n",
       "2   a c     a      c           2    0.565102       6       4   0.000000   \n",
       "\n",
       "   entropy_2   assoc_f   assoc_b  \n",
       "0   0.015141  0.043196  0.074341  \n",
       "1   0.000000  0.620430  0.404903  \n",
       "2   0.000000  0.316464  0.239136  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = mwu_measures.get_mwu_scores(['b d', 'c b', 'a c'], parallel=True) \n",
    "y['dispersion'] = 1 - y['dispersion']\n",
    "y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use real data and a real corpus. I used the BNC corpus because it's what I have at hand. This is currently the only corpus supported, but I'll add others soon. You have to get your own copy of the BNC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_measures.process_corpus('bnc', 'small_corpus.txt', chunk_size=100000, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the multiword units from Muraki et al., 2022 (provided in the directory), from here: https://osf.io/ksypa/. For now, we can only use the bigrams. All bigrams not occurring in the BNC will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_examples = pd.read_csv('MultiwordExpression_Concreteness_Ratings.csv')\n",
    "mwu_examples['length'] = mwu_examples['Expression'].apply(lambda x: len(x.split()))\n",
    "mwu_examples = mwu_examples.loc[mwu_examples['length'] == 2]\n",
    "mwu_examples['Expression'] = mwu_examples['Expression'].apply(lambda x: x.lower())\n",
    "print(f'Number of possible bigrams: {len(mwu_examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_scores = mwu_measures.get_mwu_scores(mwu_examples['Expression'][0:40], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\contr\\anaconda3\\envs\\mwu_measures\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "mwu_scores = mwu_measures.get_mwu_scores(mwu_examples['Expression'][0:40], normalize=False, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_scores = mwu_measures.get_mwu_scores(mwu_examples['Expression'][0:100], normalize=True, entropy_limits=[-0.1, 0.1], scale_entropy=True, verbose=False, track_progress=True)\n",
    "# TODO: this could very easily be parallel https://dask.pydata.org/en/latest/\n",
    "# TODO: https://superfastpython.com/learning-paths/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my test computer, this took around 6 minutes, including the normalization step. In my laptop, it was more like 15. We can see how many we had to skip because they're not in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ngrams that occur in BNC: {len(mwu_scores['normalized'])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something very sloppy just as an illustration: relationship between concreteness and the MWU measures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_examples_filter = mwu_examples.loc[mwu_examples['Expression'].isin(list(mwu_scores['normalized']['ngram']))]\n",
    "concreteness_mwu = pd.merge(mwu_examples_filter, mwu_scores['normalized'], how='left', left_on='Expression', right_on='ngram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concreteness_mwu = concreteness_mwu.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y, X = dmatrices('Mean_C ~ token_freq + dispersion + type_1 + type_2 + entropy_1 + entropy_2 + assoc_f + assoc_b', data=concreteness_mwu, return_type='dataframe')\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We can also take an MWU score based on this. First we can take an average, and compare it with a weighted average. This will be part of the package shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_scores = concreteness_mwu[['token_freq', 'dispersion', 'type_1', 'type_2', 'entropy_1', 'entropy_2', 'assoc_f', 'assoc_b']]\n",
    "concreteness_mwu['mwu_score'] = only_scores.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concreteness_mwu['mwu_weighted_1'] = only_scores.apply(lambda x: np.average(x, weights=[0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]), axis=1)\n",
    "concreteness_mwu['mwu_weighted_2'] = only_scores.apply(lambda x: np.average(x, weights=[0.1, 0.3, 0.05, 0.05, 0.2, 0.2, 0.05, 0.05]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"mwu_score\", y=\"Mean_C\", data=concreteness_mwu, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"mwu_weighted_1\", y=\"Mean_C\", data=concreteness_mwu, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"mwu_weighted_2\", y=\"Mean_C\", data=concreteness_mwu, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the most interesting relationship, but it's a living. There you go!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwu_measures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
